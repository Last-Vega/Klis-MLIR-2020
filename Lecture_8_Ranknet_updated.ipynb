{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5yg4nycCafH"
   },
   "source": [
    "# Outline\n",
    "\n",
    "## 1. Example Program: Viewing ranking as a simple regression problem\n",
    "\n",
    "## 2. Example Program: Enhanced implementation based on PyTorch\n",
    "\n",
    "## 3. Example Program: RankNet based on PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgICSzAgCkJQ"
   },
   "source": [
    "### 1.1 Import libariries & mount data folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NX2vbzinCoYL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFDqvp11TR-H",
    "outputId": "d8cf0c3f-4713-42cb-e439-e66895ca44ed"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tA0fGRexC2oE"
   },
   "source": [
    "### 1.2 The program for loading the example data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YZPE_1k0C3rd"
   },
   "outputs": [],
   "source": [
    "# The function for loading data\n",
    "def load_LETOR4(file, num_features=46):\n",
    "\t'''\n",
    "\t:param file: the input file\n",
    "\t:param num_features: the number of features\n",
    "\t:return: the list of tuples, each tuple consists of qid, doc_reprs, doc_labels\n",
    "\t'''\n",
    "  \n",
    "\tfeature_cols = [str(f_index) for f_index in range(1, num_features + 1)]\n",
    "\n",
    "\tdf = pd.read_csv(file, sep=\" \", header=None)\n",
    "\tdf.drop(columns=df.columns[[-2, -3, -5, -6, -8, -9]], axis=1, inplace=True)  # remove redundant keys\n",
    "\tassert num_features == len(df.columns) - 5\n",
    "\n",
    "\tfor c in range(1, num_features +2):           \t\t\t\t\t\t\t # remove keys per column from key:value\n",
    "\t\tdf.iloc[:, c] = df.iloc[:, c].apply(lambda x: x.split(\":\")[1])\n",
    "\n",
    "\tdf.columns = ['rele_truth', 'qid'] + feature_cols + ['#docid', 'inc', 'prob']\n",
    "\n",
    "\tfor c in ['rele_truth'] + feature_cols:\n",
    "\t\tdf[c] = df[c].astype(np.float32)\n",
    "\n",
    "\tdf['rele_binary'] = (df['rele_truth'] > 0).astype(np.float32)  # additional binarized column for later filtering\n",
    "\n",
    "\tlist_Qs = []\n",
    "\tqids = df.qid.unique()\n",
    "\tnp.random.shuffle(qids)\n",
    "\tfor qid in qids:\n",
    "\t\tsorted_qdf = df[df.qid == qid].sort_values('rele_truth', ascending=False)\n",
    "\n",
    "\t\tdoc_reprs = sorted_qdf[feature_cols].values\n",
    "\t\tdoc_labels = sorted_qdf['rele_truth'].values\n",
    "\n",
    "\t\tlist_Qs.append((qid, doc_reprs, doc_labels))\n",
    "\n",
    "\t#if buffer: pickle_save(list_Qs, file=perquery_file)\n",
    "\n",
    "\treturn list_Qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkMlvFPDNrd7"
   },
   "source": [
    "#### The program for computing nDCG score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "G7ZbSRirNveg"
   },
   "outputs": [],
   "source": [
    "def discounted_cumu_gain_at_k(sorted_labels, cutoff):\n",
    "\t'''\n",
    "\t:param sorted_labels: ranked labels (either standard or predicted by a system) in the form of np array\n",
    "\t:param max_cutoff: the maximum rank position to be considered\n",
    "\t:param multi_lavel_rele: either the case of multi-level relevance or the case of listwise int-value, e.g., MQ2007-list\n",
    "\t:return: cumulative gains for each rank position\n",
    "\t'''\n",
    "\tnums = np.power(2.0, sorted_labels[0:cutoff]) - 1.0\n",
    "\n",
    "\tdenoms = np.log2(np.arange(cutoff) + 2.0)  # discounting factor\n",
    "\tdited_cumu_gain = np.sum(nums / denoms)\n",
    "\n",
    "\treturn dited_cumu_gain\n",
    "\n",
    "def ndcg_at_k(sys_sorted_labels, ideal_sorted_labels, k):\n",
    "\tsys_discounted_cumu_gain_at_k = discounted_cumu_gain_at_k(sys_sorted_labels, cutoff=k)\n",
    "\tideal_discounted_cumu_gain_at_k = discounted_cumu_gain_at_k(ideal_sorted_labels, cutoff=k)\n",
    "\tndcg_at_k = sys_discounted_cumu_gain_at_k / ideal_discounted_cumu_gain_at_k\n",
    "\treturn ndcg_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHEKMXHdN3rj"
   },
   "source": [
    "### 1.3 The training prgoram\n",
    "\n",
    "Note: this program is based on the previous regression program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vdL7Cx-sDdOA"
   },
   "outputs": [],
   "source": [
    "def reg_gradient_descent(list_Qs, theta, learning_rate=0.001, repeat_times=5):\n",
    "  cost_history = np.zeros(repeat_times)\n",
    "\n",
    "  for k in range(repeat_times): # number of iterations, i.e., epochs\n",
    "    for (qid, train_X, train_Y) in list_Qs: # the training dataset\n",
    "      m = len(train_Y)    # the number of documents that are associated with the same query\n",
    "      for i in range(m):  # perform regression for each document\n",
    "        x = train_X[i, :] # one document's feature vector\n",
    "        y = train_Y[i]    # the corresponding truth label\n",
    "\n",
    "        prediction = np.dot(x, theta)       # prediction\n",
    "\n",
    "        theta = theta - learning_rate*(x*(prediction - y)) # gradient descent\n",
    "\n",
    "    cost=0\n",
    "    for (qid, train_X, train_Y) in list_Qs:\n",
    "      predictions_per_query = train_X.dot(theta)\n",
    "      m = len(train_Y)\n",
    "      cost_per_query = 0.5 / m * np.sum(np.square(predictions_per_query-train_Y))\n",
    "      cost += cost_per_query\n",
    "\n",
    "    cost_history[k]  = cost # record the cost/loss per epoch\n",
    "        \n",
    "  return theta, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrtIWu5bOF17"
   },
   "source": [
    "### 1.4 The evaluation program for testing the ranking model based on nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wLPmpm0LG228"
   },
   "outputs": [],
   "source": [
    "def evaluate(test_list_Qs, optimized_theta, k=5):\n",
    "  nDCG=0.0\n",
    "  count = 0.0 # count the number of test queries\n",
    "  for (qid, test_X, test_Y) in test_list_Qs:\n",
    "    sum_per_query = np.sum(test_Y)\n",
    "    m = len(test_Y)\n",
    "    if m < k or sum_per_query <= 0: # filter out queries that: (1) include less documents than k; (2) include no relevant documents\n",
    "      continue\n",
    "    else:\n",
    "      count += 1\n",
    "    \n",
    "    predictions_per_query = test_X.dot(optimized_theta) # the predictions with respect to one query\n",
    "\n",
    "    ideal_sorted_labels = np.sort(test_Y)               # the default is ascending order\n",
    "    ideal_sorted_labels = np.flip(ideal_sorted_labels)  # convert to the descending order\n",
    "    #print('ideal_sorted_labels', ideal_sorted_labels)\n",
    "\n",
    "    sorted_pred_indice = np.argsort(-predictions_per_query) # get the indice that sort the predictions in a descending order\n",
    "    sys_sorted_labels = test_Y[sorted_pred_indice]          # get the corresponding ranking of standard labels \n",
    "    #print('sys_sorted_labels', sys_sorted_labels)\n",
    "\n",
    "    nDCG_per_query = ndcg_at_k(sys_sorted_labels=sys_sorted_labels, ideal_sorted_labels=ideal_sorted_labels, k=k)\n",
    "    nDCG += nDCG_per_query\n",
    "\n",
    "  nDCG = nDCG/count # using the average nDCG\n",
    "  return nDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1FmKey8OPDM"
   },
   "source": [
    "### 1.5 Demonstration: how to learn a ranking model based on linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 922
    },
    "id": "UdD_qwpCE-64",
    "outputId": "b3d32e90-ad85-4d11-f9ba-8e2d89212481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random initialization of parameters: [ 0.85776866  1.00799652 -0.88313471 -2.2711098  -0.84464153 -0.61061679\n",
      " -1.8559587  -1.47175028  1.44258784 -0.22970843  0.29991886 -0.20918319\n",
      "  0.09255505  0.71007679 -1.84699591  0.91671578  0.44965358  0.60020198\n",
      "  0.68970646 -0.91030078 -0.30227853  0.19215877  0.75386864  0.8512491\n",
      "  0.37353769  0.30352645  0.28777565 -0.53081714 -1.3512454   0.50425375\n",
      "  0.08701794  1.37650525 -0.96959355 -0.42665202  1.0870602  -1.89107535\n",
      " -2.20230667 -0.17842651  0.74711278  0.02100249  0.66012908  0.59895496\n",
      "  0.96407346  0.13399314 -0.12083303 -1.00968077]\n",
      "\n",
      " Optimized parameters:[ 9.03120206e-01  6.00416426e-01 -2.24940886e-01 -1.02532120e+00\n",
      " -7.24326393e-01 -6.10616795e-01 -1.85595870e+00 -1.47175028e+00\n",
      "  1.44258784e+00 -2.29708427e-01  9.21137812e-01 -4.95476429e-01\n",
      "  4.47077601e-01  1.25230433e+00 -1.16550758e+00  9.55998587e-01\n",
      "  3.70946121e-03 -1.31350965e-03  9.06425573e-02 -8.71772372e-01\n",
      "  8.14741478e-01 -2.28117510e-01  1.21125388e-02  3.41493728e-01\n",
      "  1.31045158e-01  2.85639928e-01  4.61378693e-02 -3.94001880e-01\n",
      " -2.24803889e-01 -1.28600238e-01 -3.73653737e-01  5.49294649e-01\n",
      " -8.19923086e-02  1.41312119e-01  7.15270895e-01 -1.01711925e+00\n",
      " -5.85703661e-01 -1.82519823e-01  3.10667543e-01  3.74133848e-03\n",
      " -1.08970554e-02 -6.50958188e-04  6.10092476e-03 -4.93203699e-02\n",
      " -1.10867342e-01 -1.00968077e+00]\n",
      "\n",
      " The nDCG score of the optimized ranking model is: 0.39825534758840925\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fedbbe09c70>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "repeat_times = 10\n",
    "X_Dimension = 46\n",
    "\n",
    "debug = True # print some information if needed\n",
    "\n",
    "initial_theta = np.random.randn(X_Dimension) # initialization of the prameters\n",
    "if debug:\n",
    "  print('Random initialization of parameters: {}'.format(initial_theta))\n",
    "\n",
    "# load the training data\n",
    "# file = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/vali_as_train.txt'\n",
    "file = './vali_as_train.txt'\n",
    "train_list_Qs = load_LETOR4(file=file)\n",
    "\n",
    "#training the model based on gradient descent algorithm\n",
    "optimized_theta, cost_history = reg_gradient_descent(train_list_Qs, initial_theta, learning_rate=0.001, repeat_times=repeat_times)\n",
    "\n",
    "if debug:\n",
    "  print('\\n Optimized parameters:{}'.format(optimized_theta))\n",
    "\n",
    "# evaluate the ranking model by computing its nDCG score\n",
    "# load the test data\n",
    "# file = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/test.txt'\n",
    "file = './test.txt'\n",
    "test_list_Qs = load_LETOR4(file=file)\n",
    "\n",
    "nDCG = evaluate(test_list_Qs=test_list_Qs, optimized_theta=optimized_theta)\n",
    "print('\\n The nDCG score of the optimized ranking model is:', nDCG)\n",
    "\n",
    "\n",
    "# show the cost variation w.r.t. the training process\n",
    "print()\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "ax.set_ylabel('Cost')\n",
    "ax.set_xlabel('Number of times')\n",
    "ax.plot(range(repeat_times), cost_history[:repeat_times], 'b.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KuFfBVUUQZa"
   },
   "source": [
    "### 2.1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-aT9BLoFPAm",
    "outputId": "01bf9165-6b20-4efd-e1bd-4bf2bdaa10ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ptranking in /Users/watanabeshingo/opt/anaconda3/lib/python3.8/site-packages (0.0.3)\r\n",
      "Requirement already satisfied: tqdm in /Users/watanabeshingo/opt/anaconda3/lib/python3.8/site-packages (from ptranking) (4.47.0)\r\n",
      "Requirement already satisfied: numpy in /Users/watanabeshingo/opt/anaconda3/lib/python3.8/site-packages (from ptranking) (1.18.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ptranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2SvBcfk2sL2"
   },
   "source": [
    "### 2.2 Import necessary classes provided by PTRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x77KDXpnUrvR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from ptranking.data.data_utils import LTRDataset, SPLIT_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbFRHchC25Zh"
   },
   "source": [
    "### 2.3 Define a neural ranking class\n",
    "\n",
    "For more details, please refer to: https://wildltr.github.io/ptranking/how_to_start/Develop_A_New_Model/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tkvzo9_EWwly"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from ptranking.base.ranker import NeuralRanker\n",
    "\n",
    "mse = nn.MSELoss() # mean square error function provided by PyTorch\n",
    "\n",
    "class MLIRMSE(NeuralRanker):\n",
    "\tdef __init__(self, sf_para_dict=None, gpu=False, device=None):\n",
    "\t\tsuper(MLIRMSE, self).__init__(id='RankMSE', sf_para_dict=sf_para_dict, gpu=gpu, device=device)\n",
    "\t\tself.TL_AF = self.get_tl_af()\n",
    "\n",
    "\tdef inner_train(self, batch_pred, batch_label, **kwargs):\n",
    "\t\t'''\n",
    "\t\t:param batch_preds: [batch, ranking_size] each row represents the relevance predictions for documents within a ltr_adhoc\n",
    "\t\t:param batch_stds: [batch, ranking_size] each row represents the standard relevance grades for documents within a ltr_adhoc\n",
    "\t\t:return:\n",
    "\t\t'''\n",
    "\n",
    "\t\tbatch_loss = mse(batch_pred, batch_label)\n",
    "\t\t# gradient back-propagation\n",
    "\t\tself.optimizer.zero_grad()\t\n",
    "\t\tbatch_loss.backward()\n",
    "\t\tself.optimizer.step()\n",
    "\n",
    "\t\treturn batch_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShH5-C2J3Awk"
   },
   "source": [
    "### 2.4 Define a neural scoring fuction\n",
    "\n",
    "It is a component of the NeuralRanker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mTfjsT5eYW5y"
   },
   "outputs": [],
   "source": [
    "from ptranking.ltr_adhoc.eval.parameter import ScoringFunctionParameter\n",
    "\n",
    "\n",
    "class MLIRSFP(ScoringFunctionParameter):\n",
    "    \"\"\"\n",
    "    The parameter class w.r.t. a neural scoring fuction\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MLIRSFP, self).__init__()\n",
    "\n",
    "    def default_para_dict(self):\n",
    "        \"\"\"\n",
    "        A default setting of the hyper-parameters of the stump neural scoring function.\n",
    "        \"\"\"\n",
    "        # feed-forward neural networks\n",
    "        ffnns_para_dict = dict(num_layers=5, HD_AF='R', HN_AF='R', TL_AF='S', apply_tl_af=True, BN=True, RD=False, FBN=False)\n",
    "\n",
    "        sf_para_dict = dict()\n",
    "        sf_para_dict['id'] = self.model_id\n",
    "        sf_para_dict[self.model_id] = ffnns_para_dict\n",
    "\n",
    "        self.sf_para_dict = sf_para_dict\n",
    "        return sf_para_dict\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "My32Q77g3HE8"
   },
   "source": [
    "### 2.5 Perform learning-to-rank based on PTRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oFNG0J0YUjPw",
    "outputId": "9d2a5eec-7b9e-4afb-f0ae-9443e43475b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4862, 0.4869, 0.5149])\n"
     ]
    }
   ],
   "source": [
    "from ptranking.data.data_utils import get_data_meta\n",
    "from ptranking.ltr_adhoc.eval.eval_utils import ndcg_at_ks, ndcg_at_k\n",
    "from ptranking.metric.adhoc_metric import torch_nDCG_at_k, torch_nDCG_at_ks\n",
    "\n",
    "gpu, device = False, None\n",
    "\n",
    "##- Data loading -##\n",
    "# file_train = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/vali_as_train.txt'\n",
    "\n",
    "# file_test = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/test.txt'\n",
    "\n",
    "\n",
    "file_train = './vali_as_train.txt'\n",
    "file_test = './test.txt'\n",
    "\n",
    "train_data = LTRDataset(data_id='MQ2007_Super', file=file_train, split_type=SPLIT_TYPE.Train, batch_size=1, shuffle=True, presort=True, data_dict=None, eval_dict=None, buffer=False)\n",
    "\n",
    "test_data = LTRDataset(data_id='MQ2007_Super', file=file_test, split_type=SPLIT_TYPE.Test, shuffle=False, data_dict=None, batch_size=1, buffer=False)\n",
    "\n",
    "data_meta = get_data_meta(data_id='MQ2007_Super')\n",
    "\n",
    "sf_para_dict = MLIRSFP().default_para_dict()\n",
    "\n",
    "sf_para_dict['ffnns'].update(dict(num_features=data_meta['num_features']))\n",
    "\n",
    "\n",
    "# Initialize the ranking class as a ranker\n",
    "mlir_ranker = MLIRMSE(sf_para_dict=sf_para_dict)\n",
    "\n",
    "# Training\n",
    "epoch_loss = torch.cuda.FloatTensor([0.0]) if gpu else torch.FloatTensor([0.0])\n",
    "\n",
    "# Training for each query\n",
    "for qid, batch_rankings, batch_stds in train_data: # _, [batch, ranking_size, num_features], [batch, ranking_size]\n",
    "    if gpu: batch_rankings, batch_stds = batch_rankings.to(device), batch_stds.to(device)\n",
    "\n",
    "    batch_loss, stop_training = mlir_ranker.train(batch_rankings, batch_stds, qid=qid)\n",
    "\n",
    "    #print(batch_loss)\n",
    "    epoch_loss += batch_loss.item()\n",
    "\n",
    "\n",
    "# Testing\n",
    "ks=[1, 5, 10]\n",
    "sum_ndcg_at_ks = torch.zeros(len(ks))\n",
    "cnt = torch.zeros(1)\n",
    "already_sorted = True if test_data.presort else False\n",
    "for qid, batch_ranking, batch_labels in test_data: # _, [batch, ranking_size, num_features], [batch, ranking_size]\n",
    "\n",
    "    if torch.sum(batch_labels) <=0: # filter dumb queries\n",
    "      continue\n",
    "\n",
    "    if gpu: batch_ranking = batch_ranking.to(device)\n",
    "    batch_rele_preds = mlir_ranker.predict(batch_ranking)\n",
    "    if gpu: batch_rele_preds = batch_rele_preds.cpu()\n",
    "\n",
    "    _, batch_sorted_inds = torch.sort(batch_rele_preds, dim=1, descending=True)\n",
    "\n",
    "    batch_sys_sorted_labels = torch.gather(batch_labels, dim=1, index=batch_sorted_inds)\n",
    "    if already_sorted:\n",
    "        batch_ideal_sorted_labels = batch_labels\n",
    "    else:\n",
    "        batch_ideal_sorted_labels, _ = torch.sort(batch_labels, dim=1, descending=True)\n",
    "\n",
    "    batch_ndcg_at_ks = torch_nDCG_at_ks(batch_sys_sorted_labels=batch_sys_sorted_labels, batch_ideal_sorted_labels=batch_ideal_sorted_labels, ks=ks)\n",
    "\n",
    "    # default batch_size=1 due to testing data\n",
    "    sum_ndcg_at_ks = torch.add(sum_ndcg_at_ks, torch.squeeze(batch_ndcg_at_ks, dim=0))\n",
    "    cnt += 1\n",
    "\n",
    "avg_ndcg_at_ks = sum_ndcg_at_ks/cnt\n",
    "print(avg_ndcg_at_ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eX6RrqOn52Qu"
   },
   "source": [
    "### 3.1 Define a neural ranking class: RankNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mxPDtlfI575G"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ptranking.base.ranker import NeuralRanker\n",
    "\n",
    "class RankNet(NeuralRanker):\n",
    "  def __init__(self, sf_para_dict=None, gpu=False, device=None):\n",
    "    super(RankNet, self).__init__(id='RankNet', sf_para_dict=sf_para_dict, gpu=gpu, device=device)\n",
    "    self.sigma = 1.0\n",
    "    \n",
    "  def inner_train(self, batch_pred, batch_label, **kwargs):\n",
    "    '''\n",
    "    :param batch_preds: [batch, ranking_size] each row represents the relevance predictions for documents within a ltr_adhoc\n",
    "    :param batch_label:  [batch, ranking_size] each row represents the standard relevance grades for documents within a ltr_adhoc\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    print('batch_pred', batch_pred.size())\n",
    "    print('batch_label', batch_label.size())\n",
    "\n",
    "    batch_s_ij = torch.unsqueeze(batch_pred, dim=2) - torch.unsqueeze(batch_pred, dim=1)  # computing pairwise differences w.r.t. predictions, i.e., s_i - s_j\n",
    "    batch_p_ij = 1.0 / (torch.exp(-self.sigma * batch_s_ij) + 1.0)\n",
    "\n",
    "    batch_std_diffs = torch.unsqueeze(batch_label, dim=2) - torch.unsqueeze(batch_label, dim=1)  # computing pairwise differences w.r.t. standard labels, i.e., S_{ij}\n",
    "    batch_Sij = torch.clamp(batch_std_diffs, min=-1.0, max=1.0)  # ensuring S_{ij} \\in {-1, 0, 1}\n",
    "    batch_std_p_ij = 0.5 * (1.0 + batch_Sij)\n",
    "f\n",
    "    # about reduction, both mean & sum would work, mean seems straightforward due to the fact that the number of pairs differs from query to query\n",
    "    batch_loss = F.binary_cross_entropy(input=torch.triu(batch_p_ij, diagonal=1), target=torch.triu(batch_std_p_ij, diagonal=1), reduction='mean')\n",
    "\n",
    "    self.optimizer.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    self.optimizer.step()\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdvCezl6BK8B"
   },
   "source": [
    "### 2.1 Formulation\n",
    "\n",
    "Given two documents $d_i$ and $d_j$ that are represented as feature vectors $\\mathbf{x}_i$ and $\\mathbf{x}_j$, let $f$ be the ranking function, the ranking scores will be $s_i=f(\\mathbf{x}_i)$ and $s_j=f(\\mathbf{x}_j)$, the probability $p_{ij}$ indicating $d_i$ should be ranked higher than $d_j$ is given as\n",
    "\n",
    "$$ p_{ij}=\\frac{1}{1+\\exp(-(s_i-s_j))} $$\n",
    "\n",
    "Let $\\bar{p_{ij}}$ be the known probability that $d_i$ should be ranked higher than $d_j$, we then apply the **cross entropy cost function** that penalizes the deviation of the model output probabilities from the desired probabilities,\n",
    "\n",
    "$$ C=-\\bar{p_{ij}} \\log(p_{ij}) - (1-\\bar{p_{ij}})\\log(1-p_{ij}) $$\n",
    "\n",
    "For a given query, let $S_{ij}\\in \\{-1, 0, 1\\}$ be defined to be 1 if doc-i has been labeled to be more relevant than doc-j, âˆ’1 if doc-i has been labeled to be less relevant than doc-j, and 0 if they have the same label. In particular, we assume that the desired ranking is deterministically known, so that $\\bar{p_{ij}}=\\frac{1}{2}(1+S_{ij})$. Combining the above two equations gives\n",
    "\n",
    "$$ C=\\frac{1}{2}(1-S_{ij})(s_i-s_j) + \\log(1+\\exp(-(s_i-s_j))) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GVZV9xCE027",
    "outputId": "adbf46b8-1eaf-4bf0-fe44-b23800ef5fee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred torch.Size([1, 40]) tensor([[ 0.6920,  0.1969, -0.3121, -0.8604, -0.2938, -1.2998,  1.5896,  1.0454,\n",
      "         -0.8778,  1.2682, -0.8204, -0.3444, -0.7129,  1.1598,  0.5521, -1.0741,\n",
      "         -0.3777, -1.3503,  0.7881,  0.3172,  1.8590, -0.7932,  1.8779, -2.1982,\n",
      "         -1.3579, -0.3419,  0.2158, -1.3084, -0.6064,  0.2434, -0.3326,  0.1327,\n",
      "          0.2108,  0.6021,  1.3315, -0.4813,  0.7888, -0.2859,  1.5687,  0.5778]])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([1, 1, 40])\n",
      "batch_sij torch.Size([1, 40, 40]) tensor([[[ 0.0000,  0.4951,  1.0041,  ...,  0.9779, -0.8767,  0.1142],\n",
      "         [-0.4951,  0.0000,  0.5090,  ...,  0.4828, -1.3718, -0.3809],\n",
      "         [-1.0041, -0.5090,  0.0000,  ..., -0.0262, -1.8808, -0.8899],\n",
      "         ...,\n",
      "         [-0.9779, -0.4828,  0.0262,  ...,  0.0000, -1.8546, -0.8637],\n",
      "         [ 0.8767,  1.3718,  1.8808,  ...,  1.8546,  0.0000,  0.9909],\n",
      "         [-0.1142,  0.3809,  0.8899,  ...,  0.8637, -0.9909,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "batch_pred = torch.randn(size=(1, 40))\n",
    "print('pred', batch_pred.size(), batch_pred)\n",
    "\n",
    "print(torch.unsqueeze(batch_pred, dim=2).size())\n",
    "print(torch.unsqueeze(batch_pred, dim=1).size())\n",
    "\n",
    "batch_sij = torch.unsqueeze(batch_pred, dim=2) - torch.unsqueeze(batch_pred, dim=1)\n",
    "print('batch_sij', batch_sij.size(), batch_sij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dv6v_eUFAnhG",
    "outputId": "58dd5b7a-a47c-44e4-ee15-cb7b3e8d63ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 5., 6.])\n",
      "matrix_sij tensor([[ 0., -2., -3.],\n",
      "        [ 2.,  0., -1.],\n",
      "        [ 3.,  1.,  0.]])\n",
      "clamp_matrix_sij tensor([[ 0., -1., -1.],\n",
      "        [ 1.,  0., -1.],\n",
      "        [ 1.,  1.,  0.]])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'p_ij' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-04f335af6891>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmatrix_p_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmatrix_sij\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_ij\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmatrix_p_ij_triu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_p_ij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p_ij' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "pred = torch.Tensor([3, 5, 6]) # [s1, s2, s3]\n",
    "print(pred)\n",
    "\n",
    "matrix_sij = pred.view(-1, 1) - pred.view(1, -1) # it computes si - sj\n",
    "print('matrix_sij', matrix_sij)\n",
    "\n",
    "clamp_matrix_sij = torch.clamp(matrix_sij, min=-1.0, max=1.0)\n",
    "print('clamp_matrix_sij', clamp_matrix_sij)\n",
    "\n",
    "sigma = 1.0\n",
    "matrix_p_ij = 1.0 / (torch.exp(sigma * matrix_sij) + 1.0)\n",
    "\n",
    "print(p_ij)\n",
    "\n",
    "matrix_p_ij_triu = torch.triu(matrix_p_ij, diagonal=1)\n",
    "print(matrix_p_ij_triu)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sUqVhAJ66ga"
   },
   "source": [
    "### 3.2 Perform learning-to-rank with RankNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fIQSpjD6_63",
    "outputId": "67305974-fda5-4cc8-b2e9-d2f02eb585b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 50])\n",
      "batch_label torch.Size([1, 50])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 50])\n",
      "batch_label torch.Size([1, 50])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 41])\n",
      "batch_label torch.Size([1, 41])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 50])\n",
      "batch_label torch.Size([1, 50])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 41])\n",
      "batch_label torch.Size([1, 41])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 50])\n",
      "batch_label torch.Size([1, 50])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 17])\n",
      "batch_label torch.Size([1, 17])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 45])\n",
      "batch_label torch.Size([1, 45])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 88])\n",
      "batch_label torch.Size([1, 88])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 50])\n",
      "batch_label torch.Size([1, 50])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 10])\n",
      "batch_label torch.Size([1, 10])\n",
      "batch_pred torch.Size([1, 45])\n",
      "batch_label torch.Size([1, 45])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 79])\n",
      "batch_label torch.Size([1, 79])\n",
      "batch_pred torch.Size([1, 50])\n",
      "batch_label torch.Size([1, 50])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 60])\n",
      "batch_label torch.Size([1, 60])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 59])\n",
      "batch_label torch.Size([1, 59])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 77])\n",
      "batch_label torch.Size([1, 77])\n",
      "batch_pred torch.Size([1, 50])\n",
      "batch_label torch.Size([1, 50])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 56])\n",
      "batch_label torch.Size([1, 56])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 50])\n",
      "batch_label torch.Size([1, 50])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 41])\n",
      "batch_label torch.Size([1, 41])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 50])\n",
      "batch_label torch.Size([1, 50])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 42])\n",
      "batch_label torch.Size([1, 42])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 48])\n",
      "batch_label torch.Size([1, 48])\n",
      "batch_pred torch.Size([1, 52])\n",
      "batch_label torch.Size([1, 52])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 42])\n",
      "batch_label torch.Size([1, 42])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "batch_pred torch.Size([1, 40])\n",
      "batch_label torch.Size([1, 40])\n",
      "tensor([0.4851, 0.4955, 0.5212])\n"
     ]
    }
   ],
   "source": [
    "from ptranking.data.data_utils import get_data_meta\n",
    "from ptranking.ltr_adhoc.eval.eval_utils import ndcg_at_ks, ndcg_at_k\n",
    "from ptranking.metric.adhoc_metric import torch_nDCG_at_k, torch_nDCG_at_ks\n",
    "\n",
    "gpu, device = False, None\n",
    "\n",
    "##- Data loading -##\n",
    "# file_train = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/vali_as_train.txt'\n",
    "\n",
    "# file_test = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/test.txt'\n",
    "\n",
    "file_train = './vali_as_train.txt'\n",
    "file_test = './test.txt'\n",
    "\n",
    "train_data = LTRDataset(data_id='MQ2007_Super', file=file_train, split_type=SPLIT_TYPE.Train, batch_size=1, shuffle=True, presort=True, data_dict=None, eval_dict=None, buffer=False)\n",
    "\n",
    "test_data = LTRDataset(data_id='MQ2007_Super', file=file_test, split_type=SPLIT_TYPE.Test, shuffle=False, data_dict=None, batch_size=1, buffer=False)\n",
    "\n",
    "data_meta = get_data_meta(data_id='MQ2007_Super')\n",
    "\n",
    "sf_para_dict = MLIRSFP().default_para_dict()\n",
    "\n",
    "sf_para_dict['ffnns'].update(dict(num_features=data_meta['num_features']))\n",
    "\n",
    "\n",
    "# Initialize the ranking class as a ranker\n",
    "mlir_ranknet = RankNet(sf_para_dict=sf_para_dict)\n",
    "\n",
    "# Training\n",
    "epoch_loss = torch.cuda.FloatTensor([0.0]) if gpu else torch.FloatTensor([0.0])\n",
    "\n",
    "# Training for each query\n",
    "for qid, batch_rankings, batch_stds in train_data: # _, [batch, ranking_size, num_features], [batch, ranking_size]\n",
    "    if gpu: batch_rankings, batch_stds = batch_rankings.to(device), batch_stds.to(device)\n",
    "\n",
    "    batch_loss, stop_training = mlir_ranknet.train(batch_rankings, batch_stds, qid=qid)\n",
    "\n",
    "    #print(batch_loss)\n",
    "    epoch_loss += batch_loss.item()\n",
    "\n",
    "\n",
    "# Testing\n",
    "ks=[1, 5, 10]\n",
    "sum_ndcg_at_ks = torch.zeros(len(ks))\n",
    "cnt = torch.zeros(1)\n",
    "already_sorted = True if test_data.presort else False\n",
    "for qid, batch_ranking, batch_labels in test_data: # _, [batch, ranking_size, num_features], [batch, ranking_size]\n",
    "\n",
    "    if torch.sum(batch_labels) <=0: # filter dumb queries\n",
    "      continue\n",
    "\n",
    "    if gpu: batch_ranking = batch_ranking.to(device)\n",
    "    batch_rele_preds = mlir_ranknet.predict(batch_ranking)\n",
    "    if gpu: batch_rele_preds = batch_rele_preds.cpu()\n",
    "\n",
    "    _, batch_sorted_inds = torch.sort(batch_rele_preds, dim=1, descending=True)\n",
    "\n",
    "    batch_sys_sorted_labels = torch.gather(batch_labels, dim=1, index=batch_sorted_inds)\n",
    "    if already_sorted:\n",
    "        batch_ideal_sorted_labels = batch_labels\n",
    "    else:\n",
    "        batch_ideal_sorted_labels, _ = torch.sort(batch_labels, dim=1, descending=True)\n",
    "\n",
    "    batch_ndcg_at_ks = torch_nDCG_at_ks(batch_sys_sorted_labels=batch_sys_sorted_labels, batch_ideal_sorted_labels=batch_ideal_sorted_labels, ks=ks)\n",
    "\n",
    "    # default batch_size=1 due to testing data\n",
    "    sum_ndcg_at_ks = torch.add(sum_ndcg_at_ks, torch.squeeze(batch_ndcg_at_ks, dim=0))\n",
    "    cnt += 1\n",
    "\n",
    "avg_ndcg_at_ks = sum_ndcg_at_ks/cnt\n",
    "print(avg_ndcg_at_ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lecture_8_Ranknet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
