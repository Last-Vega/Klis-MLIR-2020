{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "1EUE-CdAi7e-",
    "outputId": "8492a4a2-57de-4314-97ea-47e68e5f1270"
   },
   "outputs": [],
   "source": [
    "# google drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "K2Xz-oqsjBWs"
   },
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7Ghg3B-xjWly"
   },
   "outputs": [],
   "source": [
    "# The function for loading data\n",
    "def load_LETOR4(file, num_features=46):\n",
    "    '''\n",
    "    :param file: the input file\n",
    "    :param num_features: the number of features\n",
    "    :return: the list of tuples, each tuple consists of qid, doc_reprs, doc_labels\n",
    "    '''\n",
    "  \n",
    "    feature_cols = [str(f_index) for f_index in range(1, num_features + 1)]\n",
    "\n",
    "    df = pd.read_csv(file, sep=\" \", header=None)\n",
    "    df.drop(columns=df.columns[[-2, -3, -5, -6, -8, -9]], axis=1, inplace=True)  # remove redundant keys\n",
    "    assert num_features == len(df.columns) - 5\n",
    "\n",
    "    for c in range(1, num_features +2): # remove keys per column from key:value\n",
    "        df.iloc[:, c] = df.iloc[:, c].apply(lambda x: x.split(\":\")[1])\n",
    "\n",
    "    df.columns = ['rele_truth', 'qid'] + feature_cols + ['#docid', 'inc', 'prob']\n",
    "\n",
    "    for c in ['rele_truth'] + feature_cols:\n",
    "        df[c] = df[c].astype(np.float32)\n",
    "\n",
    "    df['rele_binary'] = (df['rele_truth'] > 0).astype(np.float32)  # additional binarized column for later filtering\n",
    "\n",
    "    list_Qs = []\n",
    "    qids = df.qid.unique()\n",
    "    np.random.shuffle(qids)\n",
    "    for qid in qids:\n",
    "        sorted_qdf = df[df.qid == qid].sort_values('rele_truth', ascending=False)\n",
    "\n",
    "        doc_reprs = sorted_qdf[feature_cols].values\n",
    "        doc_labels = sorted_qdf['rele_truth'].values\n",
    "\n",
    "        list_Qs.append((qid, doc_reprs, doc_labels))\n",
    "\n",
    "    #if buffer: pickle_save(list_Qs, file=perquery_file)\n",
    "\n",
    "    return list_Qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google clobal\n",
    "# train_file = '/content/drive/My Drive/KLIS-MLIR-2020/Data/vali_as_train.txt'\n",
    "# test_file = '/content/drive/My Drive/KLIS-MLIR-2020/Data/test.txt'\n",
    "\n",
    "# local jupyter notebook\n",
    "train_file = './vali_as_train.txt'\n",
    "test_file = './test.txt'\n",
    "\n",
    "train_list_Qs = load_LETOR4(file=train_file)\n",
    "test_list_Qs = load_LETOR4(file=test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0QaOXmcQkUWE"
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(m, prediction, t):\n",
    "    return (1/m) * np.sum( ( prediction - t ) **2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_xc97tXAmXem"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=20):\n",
    "    parameter = init_x\n",
    "    cost_history = np.zeros(step_num)\n",
    "    \n",
    "    for h in range(step_num):\n",
    "        for (qid, train_X, train_Y) in train_list_Qs:\n",
    "            for i in range(len(train_Y)):\n",
    "                x = train_X[i, :] \n",
    "                y = train_Y[i]    \n",
    "                prediction = np.dot(x, parameter)\n",
    "                grad = 2/float(len(train_Y)) * (x * (prediction - y))\n",
    "\n",
    "                parameter -= lr * grad\n",
    "    \n",
    "        cost=0\n",
    "        for (qid, train_X, train_Y) in train_list_Qs:\n",
    "            predictions_per_query = train_X.dot(parameter)\n",
    "            m = len(train_Y)\n",
    "            cost_per_query = mean_squared_error(m, predictions_per_query, train_Y)\n",
    "            cost += cost_per_query\n",
    "            # print(h, \":\", cost)\n",
    "        cost_history[h]  = cost # record the cost/loss per epoch\n",
    "\n",
    "    return parameter, cost_history\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discounted_cumu_gain_at_k(sorted_labels, cutoff):\n",
    "    '''\n",
    "    :param sorted_labels: ranked labels (either standard or predicted by a system) in the form of np array\n",
    "    :param max_cutoff: the maximum rank position to be considered\n",
    "    :param multi_lavel_rele: either the case of multi-level relevance or the case of listwise int-value, e.g., MQ2007-list\n",
    "    :return: cumulative gains for each rank position\n",
    "    '''\n",
    "    nums = np.power(2.0, sorted_labels[0:cutoff]) - 1.0\n",
    "    denoms = np.log2(np.arange(cutoff) + 2.0)  # discounting factor\n",
    "    dited_cumu_gain = np.sum(nums / denoms)\n",
    "\n",
    "    return dited_cumu_gain\n",
    "\n",
    "def ndcg_at_k(sys_sorted_labels, ideal_sorted_labels, k):\n",
    "    sys_discounted_cumu_gain_at_k = discounted_cumu_gain_at_k(sys_sorted_labels, cutoff=k)\n",
    "    ideal_discounted_cumu_gain_at_k = discounted_cumu_gain_at_k(ideal_sorted_labels, cutoff=k)\n",
    "    ndcg_at_k = sys_discounted_cumu_gain_at_k / ideal_discounted_cumu_gain_at_k\n",
    "    return ndcg_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LeH0uiWUtMlR"
   },
   "outputs": [],
   "source": [
    "def evaluate(test_list_Qs, optimized_theta, k=20):\n",
    "    nDCG=0.0\n",
    "    count = 0.0 # count the number of test queries\n",
    "    for (qid, test_X, test_Y) in test_list_Qs:\n",
    "        sum_per_query = np.sum(test_Y)\n",
    "        m = len(test_Y)\n",
    "        if m < k or sum_per_query <= 0: # filter out queries that: (1) include less documents than k; (2) include no relevant documents\n",
    "            continue\n",
    "        else:\n",
    "            count += 1\n",
    "    \n",
    "        predictions_per_query = test_X.dot(optimized_theta) # the predictions with respect to one query\n",
    "\n",
    "        ideal_sorted_labels = np.sort(test_Y)               # the default is ascending order\n",
    "        ideal_sorted_labels = np.flip(ideal_sorted_labels)  # convert to the descending order\n",
    "    \n",
    "\n",
    "        sorted_pred_indice = np.argsort(-predictions_per_query) # get the indice that sort the predictions in a descending order\n",
    "        sys_sorted_labels = test_Y[sorted_pred_indice]          # get the corresponding ranking of standard labels \n",
    "    \n",
    "\n",
    "        nDCG_per_query = ndcg_at_k(sys_sorted_labels=sys_sorted_labels, ideal_sorted_labels=ideal_sorted_labels, k=k)\n",
    "        nDCG += nDCG_per_query\n",
    "\n",
    "    nDCG = nDCG/count # using the average nDCG\n",
    "    return nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Optimized parameters:[-1.27623752e-01 -1.38536961e-01  6.77130846e-01 -2.54086794e-01\n",
      "  2.75158717e-01 -3.32398348e-02 -1.25653022e-01 -2.09343355e+00\n",
      "  2.15596190e+00  1.04750692e+00 -9.13864950e-03  3.30249039e-02\n",
      " -7.95766888e-01  5.25303362e-01 -2.42634014e-01  4.25805559e-01\n",
      "  8.98060187e-02  2.44756053e-04  7.55080214e-02 -2.66560067e-01\n",
      " -6.97336795e-01  3.79330880e-01  5.59105227e-01 -4.92943524e-01\n",
      "  8.61724758e-02  5.69367098e-01  1.02506320e-01 -6.39229166e-01\n",
      "  2.63727283e-01 -1.29281287e+00  3.38785465e-01  8.92102358e-01\n",
      " -2.48579458e-01 -8.90021484e-01  2.94399749e-01  5.72024745e-01\n",
      "  8.55759626e-01  5.42279019e-02 -1.63582660e-01  1.76801171e-01\n",
      "  7.03980538e-02 -1.22260900e-01  4.30650167e-02 -1.46882332e-01\n",
      " -1.76490391e-02  2.09826017e-01]\n"
     ]
    }
   ],
   "source": [
    "step_num = 20\n",
    "X_Dimension = 46\n",
    "\n",
    "debug = True # print some information if needed\n",
    "\n",
    "init_x = np.random.randn(X_Dimension)\n",
    "train_list_Qs = load_LETOR4(file=train_file)\n",
    "optimized_theta, cost_history = gradient_descent(train_list_Qs, init_x, lr=0.01, step_num=step_num)\n",
    "\n",
    "if debug:\n",
    "  print('\\n Optimized parameters:{}'.format(optimized_theta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([242.13734297, 182.50493939, 157.8455399 , 144.67545246,\n",
       "       136.49772554, 130.89664732, 126.80345341, 123.67605908,\n",
       "       121.20967038, 119.21891989, 117.58379967, 116.22252098,\n",
       "       115.0769264 , 114.10420236, 113.27193774, 112.55504455,\n",
       "       111.93375912, 111.39229383, 110.91789699, 110.50017673])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list_Qs = load_LETOR4(file=test_file)\n",
    "nDCG = evaluate(test_list_Qs=test_list_Qs, optimized_theta=optimized_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9238315ca0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print()\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "ax.set_ylabel('Cost')\n",
    "ax.set_xlabel('Number of times')\n",
    "ax.plot(range(step_num), cost_history[:step_num], 'b.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ptranking in /Users/watanabeshingo/opt/anaconda3/lib/python3.8/site-packages (0.0.3)\n",
      "Requirement already satisfied: tqdm in /Users/watanabeshingo/opt/anaconda3/lib/python3.8/site-packages (from ptranking) (4.47.0)\n",
      "Requirement already satisfied: numpy in /Users/watanabeshingo/opt/anaconda3/lib/python3.8/site-packages (from ptranking) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install ptranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ptranking.data.data_utils import LTRDataset, SPLIT_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from ptranking.base.ranker import NeuralRanker\n",
    "\n",
    "mse = nn.MSELoss() # mean square error function provided by PyTorch\n",
    "\n",
    "class MLIRMSE(NeuralRanker):\n",
    "    def __init__(self, sf_para_dict=None, gpu=False, device=None):\n",
    "        super(MLIRMSE, self).__init__(id='RankMSE', sf_para_dict=sf_para_dict, gpu=gpu, device=device)\n",
    "        self.TL_AF = self.get_tl_af()\n",
    "\n",
    "    def inner_train(self, batch_pred, batch_label, **kwargs):\n",
    "        '''\n",
    "        :param batch_preds: [batch, ranking_size] each row represents the relevance predictions for documents within a ltr_adhoc\n",
    "        :param batch_stds: [batch, ranking_size] each row represents the standard relevance grades for documents within a ltr_adhoc\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        batch_loss = mse(batch_pred, batch_label)\n",
    "        self.optimizer.zero_grad()\t\n",
    "        batch_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return batch_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptranking.ltr_adhoc.eval.parameter import ScoringFunctionParameter\n",
    "\n",
    "\n",
    "class MLIRSFP(ScoringFunctionParameter):\n",
    "    \"\"\"\n",
    "    The parameter class w.r.t. a neural scoring fuction\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MLIRSFP, self).__init__()\n",
    "\n",
    "    def default_para_dict(self):\n",
    "        \"\"\"\n",
    "        A default setting of the hyper-parameters of the stump neural scoring function.\n",
    "        \"\"\"\n",
    "        # feed-forward neural networks\n",
    "        ffnns_para_dict = dict(num_layers=5, HD_AF='R', HN_AF='R', TL_AF='S', apply_tl_af=True, BN=True, RD=False, FBN=False)\n",
    "\n",
    "        sf_para_dict = dict()\n",
    "        sf_para_dict['id'] = self.model_id\n",
    "        sf_para_dict[self.model_id] = ffnns_para_dict\n",
    "\n",
    "        self.sf_para_dict = sf_para_dict\n",
    "        return sf_para_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4724, 0.4829, 0.5163])\n"
     ]
    }
   ],
   "source": [
    "from ptranking.data.data_utils import get_data_meta\n",
    "from ptranking.ltr_adhoc.eval.eval_utils import ndcg_at_ks, ndcg_at_k\n",
    "from ptranking.metric.adhoc_metric import torch_nDCG_at_k, torch_nDCG_at_ks\n",
    "\n",
    "gpu, device = False, None\n",
    "\n",
    "##- Data loading -##\n",
    "# if colab\n",
    "# file_train = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/vali_as_train.txt'\n",
    "\n",
    "# file_test = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/test.txt'\n",
    "\n",
    "# if local jupyter notebook\n",
    "file_train = './vali_as_train.txt'\n",
    "file_test = './test.txt'\n",
    "\n",
    "\n",
    "train_data = LTRDataset(data_id='MQ2007_Super', file=file_train, split_type=SPLIT_TYPE.Train, batch_size=1, shuffle=True, presort=True, data_dict=None, eval_dict=None, buffer=False)\n",
    "\n",
    "test_data = LTRDataset(data_id='MQ2007_Super', file=file_test, split_type=SPLIT_TYPE.Test, shuffle=False, data_dict=None, batch_size=1, buffer=False)\n",
    "\n",
    "data_meta = get_data_meta(data_id='MQ2007_Super')\n",
    "\n",
    "sf_para_dict = MLIRSFP().default_para_dict()\n",
    "\n",
    "sf_para_dict['ffnns'].update(dict(num_features=data_meta['num_features']))\n",
    "\n",
    "\n",
    "# Initialize the ranking class as a ranker\n",
    "mlir_ranker = MLIRMSE(sf_para_dict=sf_para_dict)\n",
    "\n",
    "# Training\n",
    "epoch_loss = torch.cuda.FloatTensor([0.0]) if gpu else torch.FloatTensor([0.0])\n",
    "\n",
    "# Training for each query\n",
    "for qid, batch_rankings, batch_stds in train_data: # _, [batch, ranking_size, num_features], [batch, ranking_size]\n",
    "    if gpu: batch_rankings, batch_stds = batch_rankings.to(device), batch_stds.to(device)\n",
    "\n",
    "    batch_loss, stop_training = mlir_ranker.train(batch_rankings, batch_stds, qid=qid)\n",
    "\n",
    "    #print(batch_loss)\n",
    "    epoch_loss += batch_loss.item()\n",
    "\n",
    "\n",
    "# Testing\n",
    "ks=[1, 5, 10]\n",
    "sum_ndcg_at_ks = torch.zeros(len(ks))\n",
    "cnt = torch.zeros(1)\n",
    "already_sorted = True if test_data.presort else False\n",
    "for qid, batch_ranking, batch_labels in test_data: # _, [batch, ranking_size, num_features], [batch, ranking_size]\n",
    "\n",
    "    if torch.sum(batch_labels) <=0: # filter dumb queries\n",
    "      continue\n",
    "\n",
    "    if gpu: batch_ranking = batch_ranking.to(device)\n",
    "    batch_rele_preds = mlir_ranker.predict(batch_ranking)\n",
    "    if gpu: batch_rele_preds = batch_rele_preds.cpu()\n",
    "\n",
    "    _, batch_sorted_inds = torch.sort(batch_rele_preds, dim=1, descending=True)\n",
    "\n",
    "    batch_sys_sorted_labels = torch.gather(batch_labels, dim=1, index=batch_sorted_inds)\n",
    "    if already_sorted:\n",
    "        batch_ideal_sorted_labels = batch_labels\n",
    "    else:\n",
    "        batch_ideal_sorted_labels, _ = torch.sort(batch_labels, dim=1, descending=True)\n",
    "\n",
    "    batch_ndcg_at_ks = torch_nDCG_at_ks(batch_sys_sorted_labels=batch_sys_sorted_labels, batch_ideal_sorted_labels=batch_ideal_sorted_labels, ks=ks)\n",
    "\n",
    "    # default batch_size=1 due to testing data\n",
    "    sum_ndcg_at_ks = torch.add(sum_ndcg_at_ks, torch.squeeze(batch_ndcg_at_ks, dim=0))\n",
    "    cnt += 1\n",
    "\n",
    "avg_ndcg_at_ks = sum_ndcg_at_ks/cnt\n",
    "print(avg_ndcg_at_ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Task2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
