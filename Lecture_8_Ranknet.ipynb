{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5yg4nycCafH"
   },
   "source": [
    "# Outline\n",
    "\n",
    "## 1. Example Program: Viewing ranking as a simple regression problem\n",
    "\n",
    "## 2. Example Program: Enhanced implementation based on PyTorch\n",
    "\n",
    "## 3. Example Program: RankNet based on PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgICSzAgCkJQ"
   },
   "source": [
    "### 1.1 Import libariries & mount data folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1838,
     "status": "ok",
     "timestamp": 1606701886489,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "NX2vbzinCoYL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16637,
     "status": "ok",
     "timestamp": 1606701908306,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "gFDqvp11TR-H",
    "outputId": "4d27323e-d1ad-40bc-ee81-b6dd575835a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tA0fGRexC2oE"
   },
   "source": [
    "### 1.2 The program for loading the example data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 773,
     "status": "ok",
     "timestamp": 1606701911224,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "YZPE_1k0C3rd"
   },
   "outputs": [],
   "source": [
    "# The function for loading data\n",
    "def load_LETOR4(file, num_features=46):\n",
    "\t'''\n",
    "\t:param file: the input file\n",
    "\t:param num_features: the number of features\n",
    "\t:return: the list of tuples, each tuple consists of qid, doc_reprs, doc_labels\n",
    "\t'''\n",
    "  \n",
    "\tfeature_cols = [str(f_index) for f_index in range(1, num_features + 1)]\n",
    "\n",
    "\tdf = pd.read_csv(file, sep=\" \", header=None)\n",
    "\tdf.drop(columns=df.columns[[-2, -3, -5, -6, -8, -9]], axis=1, inplace=True)  # remove redundant keys\n",
    "\tassert num_features == len(df.columns) - 5\n",
    "\n",
    "\tfor c in range(1, num_features +2):           \t\t\t\t\t\t\t # remove keys per column from key:value\n",
    "\t\tdf.iloc[:, c] = df.iloc[:, c].apply(lambda x: x.split(\":\")[1])\n",
    "\n",
    "\tdf.columns = ['rele_truth', 'qid'] + feature_cols + ['#docid', 'inc', 'prob']\n",
    "\n",
    "\tfor c in ['rele_truth'] + feature_cols:\n",
    "\t\tdf[c] = df[c].astype(np.float32)\n",
    "\n",
    "\tdf['rele_binary'] = (df['rele_truth'] > 0).astype(np.float32)  # additional binarized column for later filtering\n",
    "\n",
    "\tlist_Qs = []\n",
    "\tqids = df.qid.unique()\n",
    "\tnp.random.shuffle(qids)\n",
    "\tfor qid in qids:\n",
    "\t\tsorted_qdf = df[df.qid == qid].sort_values('rele_truth', ascending=False)\n",
    "\n",
    "\t\tdoc_reprs = sorted_qdf[feature_cols].values\n",
    "\t\tdoc_labels = sorted_qdf['rele_truth'].values\n",
    "\n",
    "\t\tlist_Qs.append((qid, doc_reprs, doc_labels))\n",
    "\n",
    "\t#if buffer: pickle_save(list_Qs, file=perquery_file)\n",
    "\n",
    "\treturn list_Qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkMlvFPDNrd7"
   },
   "source": [
    "#### The program for computing nDCG score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1606701914680,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "G7ZbSRirNveg"
   },
   "outputs": [],
   "source": [
    "def discounted_cumu_gain_at_k(sorted_labels, cutoff):\n",
    "\t'''\n",
    "\t:param sorted_labels: ranked labels (either standard or predicted by a system) in the form of np array\n",
    "\t:param max_cutoff: the maximum rank position to be considered\n",
    "\t:param multi_lavel_rele: either the case of multi-level relevance or the case of listwise int-value, e.g., MQ2007-list\n",
    "\t:return: cumulative gains for each rank position\n",
    "\t'''\n",
    "\tnums = np.power(2.0, sorted_labels[0:cutoff]) - 1.0\n",
    "\n",
    "\tdenoms = np.log2(np.arange(cutoff) + 2.0)  # discounting factor\n",
    "\tdited_cumu_gain = np.sum(nums / denoms)\n",
    "\n",
    "\treturn dited_cumu_gain\n",
    "\n",
    "def ndcg_at_k(sys_sorted_labels, ideal_sorted_labels, k):\n",
    "\tsys_discounted_cumu_gain_at_k = discounted_cumu_gain_at_k(sys_sorted_labels, cutoff=k)\n",
    "\tideal_discounted_cumu_gain_at_k = discounted_cumu_gain_at_k(ideal_sorted_labels, cutoff=k)\n",
    "\tndcg_at_k = sys_discounted_cumu_gain_at_k / ideal_discounted_cumu_gain_at_k\n",
    "\treturn ndcg_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHEKMXHdN3rj"
   },
   "source": [
    "### 1.3 The training prgoram\n",
    "\n",
    "Note: this program is based on the previous regression program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 922,
     "status": "ok",
     "timestamp": 1606701917515,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "vdL7Cx-sDdOA"
   },
   "outputs": [],
   "source": [
    "def reg_gradient_descent(list_Qs, theta, learning_rate=0.001, repeat_times=5):\n",
    "  cost_history = np.zeros(repeat_times)\n",
    "\n",
    "  for k in range(repeat_times): # number of iterations, i.e., epochs\n",
    "    for (qid, train_X, train_Y) in list_Qs: # the training dataset\n",
    "      m = len(train_Y)    # the number of documents that are associated with the same query\n",
    "      for i in range(m):  # perform regression for each document\n",
    "        x = train_X[i, :] # one document's feature vector\n",
    "        y = train_Y[i]    # the corresponding truth label\n",
    "\n",
    "        prediction = np.dot(x, theta)       # prediction\n",
    "\n",
    "        theta = theta - learning_rate*(x*(prediction - y)) # gradient descent\n",
    "\n",
    "    cost=0\n",
    "    for (qid, train_X, train_Y) in list_Qs:\n",
    "      predictions_per_query = train_X.dot(theta)\n",
    "      m = len(train_Y)\n",
    "      cost_per_query = 0.5 / m * np.sum(np.square(predictions_per_query-train_Y))\n",
    "      cost += cost_per_query\n",
    "\n",
    "    cost_history[k]  = cost # record the cost/loss per epoch\n",
    "        \n",
    "  return theta, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrtIWu5bOF17"
   },
   "source": [
    "### 1.4 The evaluation program for testing the ranking model based on nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1606701920067,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "wLPmpm0LG228"
   },
   "outputs": [],
   "source": [
    "def evaluate(test_list_Qs, optimized_theta, k=5):\n",
    "  nDCG=0.0\n",
    "  count = 0.0 # count the number of test queries\n",
    "  for (qid, test_X, test_Y) in test_list_Qs:\n",
    "    sum_per_query = np.sum(test_Y)\n",
    "    m = len(test_Y)\n",
    "    if m < k or sum_per_query <= 0: # filter out queries that: (1) include less documents than k; (2) include no relevant documents\n",
    "      continue\n",
    "    else:\n",
    "      count += 1\n",
    "    \n",
    "    predictions_per_query = test_X.dot(optimized_theta) # the predictions with respect to one query\n",
    "\n",
    "    ideal_sorted_labels = np.sort(test_Y)               # the default is ascending order\n",
    "    ideal_sorted_labels = np.flip(ideal_sorted_labels)  # convert to the descending order\n",
    "    #print('ideal_sorted_labels', ideal_sorted_labels)\n",
    "\n",
    "    sorted_pred_indice = np.argsort(-predictions_per_query) # get the indice that sort the predictions in a descending order\n",
    "    sys_sorted_labels = test_Y[sorted_pred_indice]          # get the corresponding ranking of standard labels \n",
    "    #print('sys_sorted_labels', sys_sorted_labels)\n",
    "\n",
    "    nDCG_per_query = ndcg_at_k(sys_sorted_labels=sys_sorted_labels, ideal_sorted_labels=ideal_sorted_labels, k=k)\n",
    "    nDCG += nDCG_per_query\n",
    "\n",
    "  nDCG = nDCG/count # using the average nDCG\n",
    "  return nDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1FmKey8OPDM"
   },
   "source": [
    "### 1.5 Demonstration: how to learn a ranking model based on linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 854
    },
    "executionInfo": {
     "elapsed": 4948,
     "status": "ok",
     "timestamp": 1606701942708,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "UdD_qwpCE-64",
    "outputId": "84b1e555-24e2-4cad-bcdf-7ca65e0b43f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random initialization of parameters: [-0.4460262   0.87236693 -1.12623385  0.50213089  1.24191658 -0.34383778\n",
      "  1.65561736 -0.62460253  0.56036723 -1.03597604  1.15997062 -0.6006204\n",
      " -0.58821343  0.99091053 -0.27332067  0.56297578 -1.76770411 -0.69747897\n",
      " -0.66146172  1.65752958  0.68406447  2.02130202  0.7470976   0.01698607\n",
      " -0.04891889  1.16913345  0.38161288 -0.54630279 -2.05764217  0.02780227\n",
      " -0.23798705 -1.44976738  0.15907197  1.81740984  0.32024045  0.52732046\n",
      "  2.40047844  0.22037028  1.15351514  2.2108619  -1.10420248 -1.41340266\n",
      " -1.11765787 -0.4797337  -2.02121264  0.06943823]\n",
      "\n",
      " Optimized parameters:[-0.7917774   0.77838581 -0.00430169 -0.15709622  0.78691982 -0.34383778\n",
      "  1.65561736 -0.62460253  0.56036723 -1.03597604  0.66730892 -0.59388996\n",
      "  0.23295895  0.43906538 -0.90400984 -0.45454573 -0.01862757 -0.0341086\n",
      "  0.22794013  0.63622709 -0.55563703  0.79414822  0.12169078 -0.8158584\n",
      " -0.03151726  0.72543463 -0.13776029 -0.5911401  -0.29614525  0.75559081\n",
      " -0.23731309 -0.45971421 -0.32615723  0.82796076 -0.42499773 -0.29997283\n",
      "  0.86883216 -1.16632697  0.23208002  1.11019355 -0.01188    -0.02100534\n",
      "  0.04105333 -0.11151128 -0.19159411  0.06943823]\n",
      "\n",
      " The nDCG score of the optimized ranking model is: 0.4304019817737995\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1305c022b0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "repeat_times = 10\n",
    "X_Dimension = 46\n",
    "\n",
    "debug = True # print some information if needed\n",
    "\n",
    "initial_theta = np.random.randn(X_Dimension) # initialization of the prameters\n",
    "if debug:\n",
    "  print('Random initialization of parameters: {}'.format(initial_theta))\n",
    "\n",
    "# load the training data\n",
    "file = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/vali_as_train.txt'\n",
    "train_list_Qs = load_LETOR4(file=file)\n",
    "\n",
    "#training the model based on gradient descent algorithm\n",
    "optimized_theta, cost_history = reg_gradient_descent(train_list_Qs, initial_theta, learning_rate=0.001, repeat_times=repeat_times)\n",
    "\n",
    "if debug:\n",
    "  print('\\n Optimized parameters:{}'.format(optimized_theta))\n",
    "\n",
    "# evaluate the ranking model by computing its nDCG score\n",
    "# load the test data\n",
    "file = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/test.txt'\n",
    "test_list_Qs = load_LETOR4(file=file)\n",
    "\n",
    "nDCG = evaluate(test_list_Qs=test_list_Qs, optimized_theta=optimized_theta)\n",
    "print('\\n The nDCG score of the optimized ranking model is:', nDCG)\n",
    "\n",
    "\n",
    "# show the cost variation w.r.t. the training process\n",
    "print()\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "ax.set_ylabel('Cost')\n",
    "ax.set_xlabel('Number of times')\n",
    "ax.plot(range(repeat_times), cost_history[:repeat_times], 'b.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KuFfBVUUQZa"
   },
   "source": [
    "### 2.1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4228,
     "status": "ok",
     "timestamp": 1606701951989,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "s-aT9BLoFPAm",
    "outputId": "0eda3b5a-b031-431b-de55-3aa9d7f0d7e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ptranking\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/10/1f39cedc6b26bb4fc9588f700f2a18bcec8a08f5f122ad1d47d54fc57324/ptranking-0.0.3-py3-none-any.whl (115kB)\n",
      "\r",
      "\u001b[K     |██▉                             | 10kB 17.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 20kB 19.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 30kB 9.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 40kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 51kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 61kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 71kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 81kB 5.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 92kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 102kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 112kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 122kB 4.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ptranking) (1.18.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from ptranking) (4.41.1)\n",
      "Installing collected packages: ptranking\n",
      "Successfully installed ptranking-0.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install ptranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2SvBcfk2sL2"
   },
   "source": [
    "### 2.2 Import necessary classes provided by PTRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3899,
     "status": "ok",
     "timestamp": 1606701958066,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "x77KDXpnUrvR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from ptranking.data.data_utils import LTRDataset, SPLIT_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbFRHchC25Zh"
   },
   "source": [
    "### 2.3 Define a neural ranking class\n",
    "\n",
    "For more details, please refer to: https://wildltr.github.io/ptranking/how_to_start/Develop_A_New_Model/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1606701962367,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "tkvzo9_EWwly"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from ptranking.base.ranker import NeuralRanker\n",
    "\n",
    "mse = nn.MSELoss() # mean square error function provided by PyTorch\n",
    "\n",
    "class MLIRMSE(NeuralRanker):\n",
    "\tdef __init__(self, sf_para_dict=None, gpu=False, device=None):\n",
    "\t\tsuper(MLIRMSE, self).__init__(id='RankMSE', sf_para_dict=sf_para_dict, gpu=gpu, device=device)\n",
    "\t\tself.TL_AF = self.get_tl_af()\n",
    "\n",
    "\tdef inner_train(self, batch_pred, batch_label, **kwargs):\n",
    "\t\t'''\n",
    "\t\t:param batch_preds: [batch, ranking_size] each row represents the relevance predictions for documents within a ltr_adhoc\n",
    "\t\t:param batch_stds: [batch, ranking_size] each row represents the standard relevance grades for documents within a ltr_adhoc\n",
    "\t\t:return:\n",
    "\t\t'''\n",
    "\n",
    "\t\tbatch_loss = mse(batch_pred, batch_label)\n",
    "\t\t# gradient back-propagation\n",
    "\t\tself.optimizer.zero_grad()\t\n",
    "\t\tbatch_loss.backward()\n",
    "\t\tself.optimizer.step()\n",
    "\n",
    "\t\treturn batch_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShH5-C2J3Awk"
   },
   "source": [
    "### 2.4 Define a neural scoring fuction\n",
    "\n",
    "It is a component of the NeuralRanker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1606701965824,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "mTfjsT5eYW5y"
   },
   "outputs": [],
   "source": [
    "from ptranking.ltr_adhoc.eval.parameter import ScoringFunctionParameter\n",
    "\n",
    "\n",
    "class MLIRSFP(ScoringFunctionParameter):\n",
    "    \"\"\"\n",
    "    The parameter class w.r.t. a neural scoring fuction\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MLIRSFP, self).__init__()\n",
    "\n",
    "    def default_para_dict(self):\n",
    "        \"\"\"\n",
    "        A default setting of the hyper-parameters of the stump neural scoring function.\n",
    "        \"\"\"\n",
    "        # feed-forward neural networks\n",
    "        ffnns_para_dict = dict(num_layers=5, HD_AF='R', HN_AF='R', TL_AF='S', apply_tl_af=True, BN=True, RD=False, FBN=False)\n",
    "\n",
    "        sf_para_dict = dict()\n",
    "        sf_para_dict['id'] = self.model_id\n",
    "        sf_para_dict[self.model_id] = ffnns_para_dict\n",
    "\n",
    "        self.sf_para_dict = sf_para_dict\n",
    "        return sf_para_dict\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "My32Q77g3HE8"
   },
   "source": [
    "### 2.5 Perform learning-to-rank based on PTRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6369,
     "status": "ok",
     "timestamp": 1606701976100,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "oFNG0J0YUjPw",
    "outputId": "5d444368-23f9-4eeb-edc8-489b3d047679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4632, 0.4803, 0.5107])\n"
     ]
    }
   ],
   "source": [
    "from ptranking.data.data_utils import get_data_meta\n",
    "from ptranking.ltr_adhoc.eval.eval_utils import ndcg_at_ks, ndcg_at_k\n",
    "from ptranking.metric.adhoc_metric import torch_nDCG_at_k, torch_nDCG_at_ks\n",
    "\n",
    "gpu, device = False, None\n",
    "\n",
    "##- Data loading -##\n",
    "file_train = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/vali_as_train.txt'\n",
    "\n",
    "file_test = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/test.txt'\n",
    "\n",
    "train_data = LTRDataset(data_id='MQ2007_Super', file=file_train, split_type=SPLIT_TYPE.Train, batch_size=1, shuffle=True, presort=True, data_dict=None, eval_dict=None, buffer=False)\n",
    "\n",
    "test_data = LTRDataset(data_id='MQ2007_Super', file=file_test, split_type=SPLIT_TYPE.Test, shuffle=False, data_dict=None, batch_size=1, buffer=False)\n",
    "\n",
    "data_meta = get_data_meta(data_id='MQ2007_Super')\n",
    "\n",
    "sf_para_dict = MLIRSFP().default_para_dict()\n",
    "\n",
    "sf_para_dict['ffnns'].update(dict(num_features=data_meta['num_features']))\n",
    "\n",
    "\n",
    "# Initialize the ranking class as a ranker\n",
    "mlir_ranker = MLIRMSE(sf_para_dict=sf_para_dict)\n",
    "\n",
    "# Training\n",
    "epoch_loss = torch.cuda.FloatTensor([0.0]) if gpu else torch.FloatTensor([0.0])\n",
    "\n",
    "# Training for each query\n",
    "for qid, batch_rankings, batch_stds in train_data: # _, [batch, ranking_size, num_features], [batch, ranking_size]\n",
    "    if gpu: batch_rankings, batch_stds = batch_rankings.to(device), batch_stds.to(device)\n",
    "\n",
    "    batch_loss, stop_training = mlir_ranker.train(batch_rankings, batch_stds, qid=qid)\n",
    "\n",
    "    #print(batch_loss)\n",
    "    epoch_loss += batch_loss.item()\n",
    "\n",
    "\n",
    "# Testing\n",
    "ks=[1, 5, 10]\n",
    "sum_ndcg_at_ks = torch.zeros(len(ks))\n",
    "cnt = torch.zeros(1)\n",
    "already_sorted = True if test_data.presort else False\n",
    "for qid, batch_ranking, batch_labels in test_data: # _, [batch, ranking_size, num_features], [batch, ranking_size]\n",
    "\n",
    "    if torch.sum(batch_labels) <=0: # filter dumb queries\n",
    "      continue\n",
    "\n",
    "    if gpu: batch_ranking = batch_ranking.to(device)\n",
    "    batch_rele_preds = mlir_ranker.predict(batch_ranking)\n",
    "    if gpu: batch_rele_preds = batch_rele_preds.cpu()\n",
    "\n",
    "    _, batch_sorted_inds = torch.sort(batch_rele_preds, dim=1, descending=True)\n",
    "\n",
    "    batch_sys_sorted_labels = torch.gather(batch_labels, dim=1, index=batch_sorted_inds)\n",
    "    if already_sorted:\n",
    "        batch_ideal_sorted_labels = batch_labels\n",
    "    else:\n",
    "        batch_ideal_sorted_labels, _ = torch.sort(batch_labels, dim=1, descending=True)\n",
    "\n",
    "    batch_ndcg_at_ks = torch_nDCG_at_ks(batch_sys_sorted_labels=batch_sys_sorted_labels, batch_ideal_sorted_labels=batch_ideal_sorted_labels, ks=ks)\n",
    "\n",
    "    # default batch_size=1 due to testing data\n",
    "    sum_ndcg_at_ks = torch.add(sum_ndcg_at_ks, torch.squeeze(batch_ndcg_at_ks, dim=0))\n",
    "    cnt += 1\n",
    "\n",
    "avg_ndcg_at_ks = sum_ndcg_at_ks/cnt\n",
    "print(avg_ndcg_at_ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eX6RrqOn52Qu"
   },
   "source": [
    "### 3.1 Define a neural ranking class: RankNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 749,
     "status": "ok",
     "timestamp": 1606702439206,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "mxPDtlfI575G"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ptranking.base.ranker import NeuralRanker\n",
    "\n",
    "class RankNet(NeuralRanker):\n",
    "  def __init__(self, sf_para_dict=None, gpu=False, device=None):\n",
    "    super(RankNet, self).__init__(id='RankNet', sf_para_dict=sf_para_dict, gpu=gpu, device=device)\n",
    "    self.sigma = 1.0\n",
    "    \n",
    "  def inner_train(self, batch_pred, batch_label, **kwargs):\n",
    "    '''\n",
    "    :param batch_preds: [batch, ranking_size] each row represents the relevance predictions for documents within a ltr_adhoc\n",
    "    :param batch_label:  [batch, ranking_size] each row represents the standard relevance grades for documents within a ltr_adhoc\n",
    "    :return:\n",
    "    '''\n",
    "    batch_s_ij = torch.unsqueeze(batch_pred, dim=2) - torch.unsqueeze(batch_pred, dim=1)  # computing pairwise differences w.r.t. predictions, i.e., s_i - s_j\n",
    "    batch_p_ij = 1.0 / (torch.exp(-self.sigma * batch_s_ij) + 1.0)\n",
    "\n",
    "    batch_std_diffs = torch.unsqueeze(batch_label, dim=2) - torch.unsqueeze(batch_label, dim=1)  # computing pairwise differences w.r.t. standard labels, i.e., S_{ij}\n",
    "    batch_Sij = torch.clamp(batch_std_diffs, min=-1.0, max=1.0)  # ensuring S_{ij} \\in {-1, 0, 1}\n",
    "    batch_std_p_ij = 0.5 * (1.0 + batch_Sij)\n",
    "\n",
    "    # about reduction, both mean & sum would work, mean seems straightforward due to the fact that the number of pairs differs from query to query\n",
    "    batch_loss = F.binary_cross_entropy(input=torch.triu(batch_p_ij, diagonal=1), target=torch.triu(batch_std_p_ij, diagonal=1), reduction='mean')\n",
    "\n",
    "    self.optimizer.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    self.optimizer.step()\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sUqVhAJ66ga"
   },
   "source": [
    "### 3.2 Perform learning-to-rank with RankNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6274,
     "status": "ok",
     "timestamp": 1606702550314,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "5fIQSpjD6_63",
    "outputId": "ded2bd5e-f7bc-4bd2-978e-f8fa838624ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4977, 0.4965, 0.5235])\n"
     ]
    }
   ],
   "source": [
    "from ptranking.data.data_utils import get_data_meta\n",
    "from ptranking.ltr_adhoc.eval.eval_utils import ndcg_at_ks, ndcg_at_k\n",
    "from ptranking.metric.adhoc_metric import torch_nDCG_at_k, torch_nDCG_at_ks\n",
    "\n",
    "gpu, device = False, None\n",
    "\n",
    "##- Data loading -##\n",
    "file_train = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/vali_as_train.txt'\n",
    "\n",
    "file_test = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/test.txt'\n",
    "\n",
    "train_data = LTRDataset(data_id='MQ2007_Super', file=file_train, split_type=SPLIT_TYPE.Train, batch_size=1, shuffle=True, presort=True, data_dict=None, eval_dict=None, buffer=False)\n",
    "\n",
    "test_data = LTRDataset(data_id='MQ2007_Super', file=file_test, split_type=SPLIT_TYPE.Test, shuffle=False, data_dict=None, batch_size=1, buffer=False)\n",
    "\n",
    "data_meta = get_data_meta(data_id='MQ2007_Super')\n",
    "\n",
    "sf_para_dict = MLIRSFP().default_para_dict()\n",
    "\n",
    "sf_para_dict['ffnns'].update(dict(num_features=data_meta['num_features']))\n",
    "\n",
    "\n",
    "# Initialize the ranking class as a ranker\n",
    "mlir_ranknet = RankNet(sf_para_dict=sf_para_dict)\n",
    "\n",
    "# Training\n",
    "epoch_loss = torch.cuda.FloatTensor([0.0]) if gpu else torch.FloatTensor([0.0])\n",
    "\n",
    "# Training for each query\n",
    "for qid, batch_rankings, batch_stds in train_data: # _, [batch, ranking_size, num_features], [batch, ranking_size]\n",
    "    if gpu: batch_rankings, batch_stds = batch_rankings.to(device), batch_stds.to(device)\n",
    "\n",
    "    batch_loss, stop_training = mlir_ranknet.train(batch_rankings, batch_stds, qid=qid)\n",
    "\n",
    "    #print(batch_loss)\n",
    "    epoch_loss += batch_loss.item()\n",
    "\n",
    "\n",
    "# Testing\n",
    "ks=[1, 5, 10]\n",
    "sum_ndcg_at_ks = torch.zeros(len(ks))\n",
    "cnt = torch.zeros(1)\n",
    "already_sorted = True if test_data.presort else False\n",
    "for qid, batch_ranking, batch_labels in test_data: # _, [batch, ranking_size, num_features], [batch, ranking_size]\n",
    "\n",
    "    if torch.sum(batch_labels) <=0: # filter dumb queries\n",
    "      continue\n",
    "\n",
    "    if gpu: batch_ranking = batch_ranking.to(device)\n",
    "    batch_rele_preds = mlir_ranknet.predict(batch_ranking)\n",
    "    if gpu: batch_rele_preds = batch_rele_preds.cpu()\n",
    "\n",
    "    _, batch_sorted_inds = torch.sort(batch_rele_preds, dim=1, descending=True)\n",
    "\n",
    "    batch_sys_sorted_labels = torch.gather(batch_labels, dim=1, index=batch_sorted_inds)\n",
    "    if already_sorted:\n",
    "        batch_ideal_sorted_labels = batch_labels\n",
    "    else:\n",
    "        batch_ideal_sorted_labels, _ = torch.sort(batch_labels, dim=1, descending=True)\n",
    "\n",
    "    batch_ndcg_at_ks = torch_nDCG_at_ks(batch_sys_sorted_labels=batch_sys_sorted_labels, batch_ideal_sorted_labels=batch_ideal_sorted_labels, ks=ks)\n",
    "\n",
    "    # default batch_size=1 due to testing data\n",
    "    sum_ndcg_at_ks = torch.add(sum_ndcg_at_ks, torch.squeeze(batch_ndcg_at_ks, dim=0))\n",
    "    cnt += 1\n",
    "\n",
    "avg_ndcg_at_ks = sum_ndcg_at_ks/cnt\n",
    "print(avg_ndcg_at_ks)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lecture_8_Ranknet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
