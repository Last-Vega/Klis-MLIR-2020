{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5yg4nycCafH"
   },
   "source": [
    "# Outline\n",
    "\n",
    "## 1. Example Program: Viewing ranking as a simple regression problem\n",
    "\n",
    "## 2. Example Program: Enhanced implementation based on PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgICSzAgCkJQ"
   },
   "source": [
    "### 1.1 Import libariries & mount data folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1854,
     "status": "ok",
     "timestamp": 1606129952130,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "NX2vbzinCoYL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "executionInfo": {
     "elapsed": 4028,
     "status": "error",
     "timestamp": 1606129989899,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "gFDqvp11TR-H",
    "outputId": "c667e711-b6d7-422d-fe81-420c8dae7c85"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    249\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tA0fGRexC2oE"
   },
   "source": [
    "### 1.2 The program for loading the example data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZPE_1k0C3rd"
   },
   "outputs": [],
   "source": [
    "# The function for loading data\n",
    "def load_LETOR4(file, num_features=46):\n",
    "\t'''\n",
    "\t:param file: the input file\n",
    "\t:param num_features: the number of features\n",
    "\t:return: the list of tuples, each tuple consists of qid, doc_reprs, doc_labels\n",
    "\t'''\n",
    "  \n",
    "\tfeature_cols = [str(f_index) for f_index in range(1, num_features + 1)]\n",
    "\n",
    "\tdf = pd.read_csv(file, sep=\" \", header=None)\n",
    "\tdf.drop(columns=df.columns[[-2, -3, -5, -6, -8, -9]], axis=1, inplace=True)  # remove redundant keys\n",
    "\tassert num_features == len(df.columns) - 5\n",
    "\n",
    "\tfor c in range(1, num_features +2):           \t\t\t\t\t\t\t # remove keys per column from key:value\n",
    "\t\tdf.iloc[:, c] = df.iloc[:, c].apply(lambda x: x.split(\":\")[1])\n",
    "\n",
    "\tdf.columns = ['rele_truth', 'qid'] + feature_cols + ['#docid', 'inc', 'prob']\n",
    "\n",
    "\tfor c in ['rele_truth'] + feature_cols:\n",
    "\t\tdf[c] = df[c].astype(np.float32)\n",
    "\n",
    "\tdf['rele_binary'] = (df['rele_truth'] > 0).astype(np.float32)  # additional binarized column for later filtering\n",
    "\n",
    "\tlist_Qs = []\n",
    "\tqids = df.qid.unique()\n",
    "\tnp.random.shuffle(qids)\n",
    "\tfor qid in qids:\n",
    "\t\tsorted_qdf = df[df.qid == qid].sort_values('rele_truth', ascending=False)\n",
    "\n",
    "\t\tdoc_reprs = sorted_qdf[feature_cols].values\n",
    "\t\tdoc_labels = sorted_qdf['rele_truth'].values\n",
    "\n",
    "\t\tlist_Qs.append((qid, doc_reprs, doc_labels))\n",
    "\n",
    "\t#if buffer: pickle_save(list_Qs, file=perquery_file)\n",
    "\n",
    "\treturn list_Qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkMlvFPDNrd7"
   },
   "source": [
    "#### The program for computing nDCG score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7ZbSRirNveg"
   },
   "outputs": [],
   "source": [
    "def discounted_cumu_gain_at_k(sorted_labels, cutoff):\n",
    "\t'''\n",
    "\t:param sorted_labels: ranked labels (either standard or predicted by a system) in the form of np array\n",
    "\t:param max_cutoff: the maximum rank position to be considered\n",
    "\t:param multi_lavel_rele: either the case of multi-level relevance or the case of listwise int-value, e.g., MQ2007-list\n",
    "\t:return: cumulative gains for each rank position\n",
    "\t'''\n",
    "\tnums = np.power(2.0, sorted_labels[0:cutoff]) - 1.0\n",
    "\n",
    "\tdenoms = np.log2(np.arange(cutoff) + 2.0)  # discounting factor\n",
    "\tdited_cumu_gain = np.sum(nums / denoms)\n",
    "\n",
    "\treturn dited_cumu_gain\n",
    "\n",
    "def ndcg_at_k(sys_sorted_labels, ideal_sorted_labels, k):\n",
    "\tsys_discounted_cumu_gain_at_k = discounted_cumu_gain_at_k(sys_sorted_labels, cutoff=k)\n",
    "\tideal_discounted_cumu_gain_at_k = discounted_cumu_gain_at_k(ideal_sorted_labels, cutoff=k)\n",
    "\tndcg_at_k = sys_discounted_cumu_gain_at_k / ideal_discounted_cumu_gain_at_k\n",
    "\treturn ndcg_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHEKMXHdN3rj"
   },
   "source": [
    "### 1.3 The training prgoram\n",
    "\n",
    "Note: this program is based on the previous regression program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdL7Cx-sDdOA"
   },
   "outputs": [],
   "source": [
    "def reg_gradient_descent(list_Qs, theta, learning_rate=0.001, repeat_times=5):\n",
    "  cost_history = np.zeros(repeat_times)\n",
    "\n",
    "  for k in range(repeat_times): # number of iterations, i.e., epochs\n",
    "    for (qid, train_X, train_Y) in list_Qs: # the training dataset\n",
    "      m = len(train_Y)    # the number of documents that are associated with the same query\n",
    "      for i in range(m):  # perform regression for each document\n",
    "        x = train_X[i, :] # one document's feature vector\n",
    "        y = train_Y[i]    # the corresponding truth label\n",
    "\n",
    "        prediction = np.dot(x, theta)       # prediction\n",
    "\n",
    "        theta = theta - learning_rate*(x*(prediction - y)) # gradient descent\n",
    "\n",
    "    cost=0\n",
    "    for (qid, train_X, train_Y) in list_Qs:\n",
    "      predictions_per_query = train_X.dot(theta)\n",
    "      m = len(train_Y)\n",
    "      cost_per_query = 0.5 * m * np.sum(np.square(predictions_per_query-train_Y))\n",
    "      cost += cost_per_query\n",
    "\n",
    "    cost_history[k]  = cost # record the cost/loss per epoch\n",
    "        \n",
    "  return theta, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrtIWu5bOF17"
   },
   "source": [
    "### 1.4 The evaluation program for testing the ranking model based on nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLPmpm0LG228"
   },
   "outputs": [],
   "source": [
    "def evaluate(test_list_Qs, optimized_theta, k=5):\n",
    "  nDCG=0.0\n",
    "  count = 0.0 # count the number of test queries\n",
    "  for (qid, test_X, test_Y) in test_list_Qs:\n",
    "    sum_per_query = np.sum(test_Y)\n",
    "    m = len(test_Y)\n",
    "    if m < k or sum_per_query <= 0: # filter out queries that: (1) include less documents than k; (2) include no relevant documents\n",
    "      continue\n",
    "    else:\n",
    "      count += 1\n",
    "    \n",
    "    predictions_per_query = test_X.dot(optimized_theta) # the predictions with respect to one query\n",
    "\n",
    "    ideal_sorted_labels = np.sort(test_Y)               # the default is ascending order\n",
    "    ideal_sorted_labels = np.flip(ideal_sorted_labels)  # convert to the descending order\n",
    "    #print('ideal_sorted_labels', ideal_sorted_labels)\n",
    "\n",
    "    sorted_pred_indice = np.argsort(-predictions_per_query) # get the indice that sort the predictions in a descending order\n",
    "    sys_sorted_labels = test_Y[sorted_pred_indice]          # get the corresponding ranking of standard labels \n",
    "    #print('sys_sorted_labels', sys_sorted_labels)\n",
    "\n",
    "    nDCG_per_query = ndcg_at_k(sys_sorted_labels=sys_sorted_labels, ideal_sorted_labels=ideal_sorted_labels, k=k)\n",
    "    nDCG += nDCG_per_query\n",
    "\n",
    "  nDCG = nDCG/count # using the average nDCG\n",
    "  return nDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1FmKey8OPDM"
   },
   "source": [
    "### 1.5 Demonstration: how to learn a ranking model based on linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 922
    },
    "executionInfo": {
     "elapsed": 5458,
     "status": "ok",
     "timestamp": 1605836511802,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "UdD_qwpCE-64",
    "outputId": "ca1d354d-8037-47db-b83d-a21a3b30cf65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random initialization of parameters: [ 9.11178067e-01 -5.76038733e-01 -7.56432352e-01 -3.10080988e+00\n",
      "  1.05777579e+00  7.39447848e-01  3.52891209e-01  2.08065579e+00\n",
      "  2.99709110e-01  3.15223189e-01 -1.06872935e+00  1.51137306e-01\n",
      " -1.04792840e-01 -3.73001079e-01 -3.44608925e-01  6.42061337e-01\n",
      " -8.92084101e-01 -2.16751373e+00 -4.24147477e-01  6.04039538e-01\n",
      "  2.43232480e-01 -6.80492291e-01 -8.90267105e-02 -1.49162656e+00\n",
      "  1.39192665e+00  3.19284179e-01  6.85983976e-01 -3.90312304e-01\n",
      " -9.37911519e-04  5.29418193e-01 -7.75215575e-01  5.32072225e-01\n",
      "  1.34311213e+00  1.45271303e-01  7.44427055e-01  6.66068943e-01\n",
      "  8.03641929e-01  8.97238934e-01  1.27329434e-01  3.04482693e-02\n",
      "  1.54428396e+00 -1.16073570e+00 -4.93709809e-01 -4.23906257e-01\n",
      "  1.28294473e+00  7.69712851e-01]\n",
      "\n",
      " Optimized parameters:[ 0.09876928 -0.27279837 -0.07462729 -1.46644274  0.1178233   0.73944785\n",
      "  0.35289121  2.08065579  0.29970911  0.31522319 -0.41944495  0.22998108\n",
      "  0.29773113  0.4142304   0.15173159  0.05573503  0.06108406 -0.02543005\n",
      " -0.00381923  0.01403324 -0.02417877 -0.4896523   0.24263849 -0.51144888\n",
      "  0.18967888  0.03000677  0.11752894 -0.24260748 -0.24323014  0.14531849\n",
      " -0.44512365  0.28786331  1.31725487 -0.38568854 -0.00986132  0.08580959\n",
      "  0.19564402  0.53355017  0.05584474  0.46033015  0.09351403 -0.19459099\n",
      "  0.04848    -0.09251533  0.14008815  0.76971285]\n",
      "\n",
      " The nDCG score of the optimized ranking model is: 0.3997428426412317\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faf596d2630>]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA44AAAHgCAYAAADqljOXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df9BldX0n+PfHxnaMMwpKD2v4MTBKMoNOzOgj4ZmZZFs7i2icwDgmwZ0ZehNWJhPNr8psxKRqSGmm0DgZs8waqogwoONIKMYEKtEg2/LEra1GadTwQ2PsYAzNohBBzMYdOrSf/eOeTi5N86V55On7dPfrVXXr3Ps533PO51pPCW/O93xvdXcAAADg8Txt0Q0AAACwvgmOAAAADAmOAAAADAmOAAAADAmOAAAADAmOAAAADB216AbWi2OPPbZPPvnkRbcBAACwELfeeuufdfem/e0THCcnn3xyduzYseg2AAAAFqKqvvR4+0xVBQAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwXMe2b08uvni2BQAAWJSjFt0A+7d9e7JlS7J7d7JxY7JtW7K8vOiuAACAI5E7juvUysosNO7ZM9uurCy6IwAA4EglOK5TmzfP7jRu2DDbbt686I4AAIAjlamq69Ty8mx66srKLDSapgoAACyK4LiOLS8LjAAAwOKZqgoAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMDQmgXHqrqiqu6rqjv2qf9kVf1hVd1ZVb8yV39rVe2sqs9X1avm6mdNtZ1VdeFc/ZSq+sRU/82q2jjVnzF93jntP3mtviMAAMCRYC3vOF6Z5Kz5QlW9IsnZSV7S3S9K8h+m+mlJzk3youmYX6+qDVW1Icl7krw6yWlJ3jCNTZJ3Jnl3d78wyYNJzp/q5yd5cKq/exoHAADAKq1ZcOzujyd5YJ/yv0nyju5+eBpz31Q/O8nV3f1wd38xyc4kp0+vnd19V3fvTnJ1krOrqpK8Msm10/FXJTln7lxXTe+vTbJlGg8AAMAqHOxnHL8jyfdOU0h/v6pePtWPT3L33LhdU+3x6s9L8rXufmSf+qPONe1/aBoPAADAKhy1gOs9N8kZSV6e5Jqq+rsHuYe/UlUXJLkgSU466aRFtQEAALCuHew7jruSfKhnPpnkm0mOTXJPkhPnxp0w1R6v/tUkR1fVUfvUM3/MtP850/jH6O7Lunupu5c2bdr0FHw9AACAw8/BDo6/neQVSVJV35FkY5I/S3J9knOnFVFPSXJqkk8muSXJqdMKqhszW0Dn+u7uJDclef103q1JrpveXz99zrT/Y9N4AAAAVmHNpqpW1QeTbE5ybFXtSnJRkiuSXDH9RMfuJFunUHdnVV2T5LNJHknypu7eM53nzUluSLIhyRXdfed0ibckubqqfjnJp5NcPtUvT/L+qtqZ2eI8567VdwQAADgSlJtxM0tLS71jx45FtwEAALAQVXVrdy/tb9/BnqoKAADAIUZwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYEhwBAAAYGjNgmNVXVFV91XVHXO1X6qqe6rqM9PrNXP73lpVO6vq81X1qrn6WVNtZ1VdOFc/pao+MdV/s6o2TvVnTJ93TvtPXqvvCAAAcCRYyzuOVyY5az/1d3f3d0+vDydJVZ2W5NwkL5qO+fWq2lBVG5K8J8mrk5yW5A3T2CR553SuFyZ5MMn5U/38JA9O9XdP4wAAAFilNQuO3f3xJA8c4PCzk1zd3Q939xeT7Exy+vTa2d13dffuJFcnObuqKskrk1w7HX9VknPmznXV9P7aJFum8QAAAKzCIp5xfHNV3TZNZT1mqh2f5O65Mbum2uPVn5fka939yD71R51r2v/QNB4AAIBVONjB8dIkL0jy3UnuTfKrB/n6j1JVF1TVjqracf/99y+yFQAAgHXroAbH7v5Kd+/p7m8m+Y3MpqImyT1JTpwbesJUe7z6V5McXVVH7VN/1Lmm/c+Zxu+vn8u6e6m7lzZt2vStfj0AAIDD0kENjlX1/LmP/yzJ3hVXr09y7rQi6ilJTk3yySS3JDl1WkF1Y2YL6Fzf3Z3kpiSvn47fmuS6uXNtnd6/PsnHpvEAAACswlFPPGR1quqDSTYnObaqdiW5KMnmqvruJJ3kT5L86yTp7jur6pokn03ySJI3dfee6TxvTnJDkg1JrujuO6dLvCXJ1VX1y0k+neTyqX55kvdX1c7MFuc5d62+IwAAwJGg3IybWVpa6h07diy6DQAAgIWoqlu7e2l/+xaxqioAAACHEMERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERAACAoTULjlV1RVXdV1V37Gffz1VVV9Wx0+eqqkuqamdV3VZVL50bu7WqvjC9ts7VX1ZVt0/HXFJVNdWfW1U3TuNvrKpj1uo7AgAAHAnW8o7jlUnO2rdYVScmOTPJn86VX53k1Ol1QZJLp7HPTXJRku9JcnqSi+aC4KVJ3jh33N5rXZhkW3efmmTb9BkAAIBVWrPg2N0fT/LAfna9O8nPJ+m52tlJ3tczNyc5uqqen+RVSW7s7ge6+8EkNyY5a9r37O6+ubs7yfuSnDN3rqum91fN1QEAAFiFg/qMY1WdneSe7v6DfXYdn+Tuuc+7ptqovms/9SQ5rrvvnd5/OclxT033AAAAR6ajDtaFqurbkvxCZtNUD4ru7qrqx9tfVRdkNjU2J5100sFqCwAA4JByMO84viDJKUn+oKr+JMkJST5VVf9DknuSnDg39oSpNqqfsJ96knxlmsqaaXvf4zXU3Zd191J3L23atOlb+GoAAACHr4MWHLv79u7+2919cnefnNn00pd295eTXJ/kvGl11TOSPDRNN70hyZlVdcy0KM6ZSW6Y9n29qs6YVlM9L8l106WuT7J39dWtc3UAAABWYS1/juODSbYn+c6q2lVV5w+GfzjJXUl2JvmNJD+RJN39QJK3J7ller1tqmUa897pmD9O8pGp/o4k/1NVfSHJ90+fAQAAWKWaLUrK0tJS79ixY9FtAAAALERV3drdS/vbd1BXVQUAAODQIzgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwtGbBsaquqKr7quqOudrbq+q2qvpMVX20qr59qldVXVJVO6f9L507ZmtVfWF6bZ2rv6yqbp+OuaSqaqo/t6punMbfWFXHrNV3BAAAOBKs5R3HK5OctU/tXd39Xd393Ul+J8m/m+qvTnLq9LogyaXJLAQmuSjJ9yQ5PclFc0Hw0iRvnDtu77UuTLKtu09Nsm36DAAAwCqtWXDs7o8neWCf2tfnPj4rSU/vz07yvp65OcnRVfX8JK9KcmN3P9DdDya5MclZ075nd/fN3d1J3pfknLlzXTW9v2quDgAAwCocdbAvWFX/Psl5SR5K8oqpfHySu+eG7Zpqo/qu/dST5Ljuvnd6/+Ukxw16uSCzO5w56aSTVvFtAAAADn8HfXGc7v7F7j4xyQeSvHmNr9X567ua+9t/WXcvdffSpk2b1rIVAACAQ9YBBceqev+B1J6kDyT559P7e5KcOLfvhKk2qp+wn3qSfGWaypppe9+32CcAAMAR7UDvOL5o/kNVbUjysid7sao6de7j2Un+cHp/fZLzptVVz0jy0DTd9IYkZ1bVMdOiOGcmuWHa9/WqOmNaTfW8JNfNnWvv6qtb5+oAAACswvAZx6p6a5JfSPLMqtq7sE0l2Z3ksic49oNJNic5tqp2ZbY66muq6juTfDPJl5L8+DT8w0lek2Rnkm8k+dEk6e4HqurtSW6Zxr2tu/cuuPMTma3c+swkH5leSfKOJNdU1fnTNX541CcAAABjNXsM8AkGVV3c3W89CP0szNLSUu/YsWPRbQAAACxEVd3a3Uv723egU1V/p6qeNZ3sX1bVf6yqv/OUdQgAAMC6daDB8dIk36iqlyT5uSR/nNlvJwIAAHCYO9Dg+Mj00xZnJ/k/uvs9Sf7W2rUFAADAejFcHGfOn08L5fyrJN9bVU9L8vS1awsAAID14kDvOP5IkoeT/Fh3fzmz301815p1BQAAwLpxQMFxCosfSPKcqnptkv/e3Z5xBAAAOAIcUHCsqh9O8skkP5TZ7yJ+oqpev5aNAQAAsD4c6DOOv5jk5d19X5JU1aYk/2eSa9eqMQAAANaHA33G8Wl7Q+Pkq0/iWAAAAA5hB3rH8feq6oYkH5w+/0iSD69NSwAAAKwnw+BYVS9Mclx3/29V9bok/2TatT2zxXIAAAA4zD3RHcdfS/LWJOnuDyX5UJJU1T+Y9v3TNe0OAACAhXui5xSP6+7b9y1OtZPXpCMAAADWlScKjkcP9j3zqWwEAACA9emJguOOqnrjvsWq+l+T3Lo2LQEAALCePNEzjj+T5Leq6l/kr4PiUpKNSf7ZWjYGAADA+jAMjt39lST/qKpekeTFU/l3u/tja94ZAAAA68IB/Y5jd9+U5KY17gUAAIB16ImecQQAAOAIJzgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDgCAAAwJDhyRNm+Pbn44tkWAAA4MEctugE4WLZvT7ZsSXbvTjZuTLZtS5aXF90VAACsf+44csRYWZmFxj17ZtuVlUV3BAAAhwbBkSPG5s2zO40bNsy2mzcvuiMAADg0mKrKEWN5eTY9dWVlFhpNUwUAgAMjOHJEWV4WGAEA4MkyVRUAAIAhwREAAIChNQuOVXVFVd1XVXfM1d5VVX9YVbdV1W9V1dFz+95aVTur6vNV9aq5+llTbWdVXThXP6WqPjHVf7OqNk71Z0yfd077T16r7wgAAHAkWMs7jlcmOWuf2o1JXtzd35Xkj5K8NUmq6rQk5yZ50XTMr1fVhqrakOQ9SV6d5LQkb5jGJsk7k7y7u1+Y5MEk50/185M8ONXfPY0DAABgldYsOHb3x5M8sE/to939yPTx5iQnTO/PTnJ1dz/c3V9MsjPJ6dNrZ3ff1d27k1yd5OyqqiSvTHLtdPxVSc6ZO9dV0/trk2yZxgMAALAKi3zG8ceSfGR6f3ySu+f27Zpqj1d/XpKvzYXQvfVHnWva/9A0/jGq6oKq2lFVO+6///5v+QsBAAAcjhYSHKvqF5M8kuQDi7j+Xt19WXcvdffSpk2bFtkKAADAunXQf8exqv6XJK9NsqW7eyrfk+TEuWEnTLU8Tv2rSY6uqqOmu4rz4/eea1dVHZXkOdN4AAAAVuGg3nGsqrOS/HySH+zub8ztuj7JudOKqKckOTXJJ5PckuTUaQXVjZktoHP9FDhvSvL66fitSa6bO9fW6f3rk3xsLqACAADwJK3ZHceq+mCSzUmOrapdSS7KbBXVZyS5cVqv5ubu/vHuvrOqrkny2cymsL6pu/dM53lzkhuSbEhyRXffOV3iLUmurqpfTvLpJJdP9cuTvL+qdma2OM+5a/UdAQAAjgTlZtzM0tJS79ixY9FtAAAALERV3drdS/vbt8hVVQEAADgECI4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMCY4AAAAMrVlwrKorquq+qrpjrvZDVXVnVX2zqpb2Gf/WqtpZVZ+vqlfN1c+aajur6sK5+ilV9Ymp/ptVtXGqP2P6vHPaf/JafUcAAIAjwVrecbwyyVn71O5I8rokH58vVtVpSc5N8qLpmF+vqg1VtSHJe5K8OslpSd4wjU2SdyZ5d3e/MMmDSc6f6ucneXCqv3saBwAAwCqtWXDs7o8neWCf2ue6+/P7GX52kqu7++Hu/mKSnUlOn147u/uu7t6d5OokZ1dVJXllkmun469Kcs7cua6a3l+bZMs0HgAAgFVYL884Hp/k7rnPu6ba49Wfl+Rr3f3IPvVHnWva/9A0HgAAgFVYL8FxIarqgqraUVU77r///kW3AwAAsC6tl+B4T5IT5z6fMNUer/7VJEdX1VH71B91rmn/c6bxj9Hdl3X3Uncvbdq06Sn6KgAAAIeX9RIcr09y7rQi6ilJTk3yySS3JDl1WkF1Y2YL6Fzf3Z3kpiSvn47fmuS6uXNtnd6/PsnHpvEAAACswlFPPGR1quqDSTYnObaqdiW5KLPFcv5Tkk1JfreqPtPdr+ruO6vqmiSfTfJIkjd1957pPG9OckOSDUmu6O47p0u8JcnVVfXLST6d5PKpfnmS91fVzul6567VdwQAADgSlJtxM0tLS71jx45FtwEAALAQVXVrdy/tb996maoKAADAOiU4AgAAMCQ4AgAAMCQ4AgAAMCQ4Aqu2fXty8cWzLQAAh681+zkO4PC2fXuyZUuye3eycWOybVuyvLzorgAAWAvuOAKrsrIyC4179sy2KyuL7ggAgLUiOAKrsnnz7E7jhg2z7ebNi+4IAIC1YqoqsCrLy7PpqSsrs9BomioAwOFLcARWbXlZYAQAOBKYqgoAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4AgAAMCQ4Aiwjmzfnlx88WwLALBeHLXoBgCY2b492bIl2b072bgx2bYtWV5edFcAAO44AqwbKyuz0Lhnz2y7srLojgAAZgRHgHVi8+bZncYNG2bbzZsX3REAwIypqgDrxPLybHrqysosNJqmCgCsF4IjwDqyvCwwAgDrj6mqAAAADK1ZcKyqK6rqvqq6Y6723Kq6saq+MG2PmepVVZdU1c6quq2qXjp3zNZp/Beqautc/WVVdft0zCVVVaNrAAAAsDprecfxyiRn7VO7MMm27j41ybbpc5K8Osmp0+uCJJcmsxCY5KIk35Pk9CQXzQXBS5O8ce64s57gGgAAAKzCmgXH7v54kgf2KZ+d5Krp/VVJzpmrv69nbk5ydFU9P8mrktzY3Q9094NJbkxy1rTv2d19c3d3kvftc679XQMAAIBVONjPOB7X3fdO77+c5Ljp/fFJ7p4bt2uqjeq79lMfXQMAAIBVWNjiONOdwl7kNarqgqraUVU77r///rVsBQAA4JB1sIPjV6Zpppm29031e5KcODfuhKk2qp+wn/roGo/R3Zd191J3L23atGnVXwoAAOBwdrCD4/VJ9q6MujXJdXP186bVVc9I8tA03fSGJGdW1THTojhnJrlh2vf1qjpjWk31vH3Otb9rAAAAsApHrdWJq+qDSTYnObaqdmW2Ouo7klxTVecn+VKSH56GfzjJa5LsTPKNJD+aJN39QFW9Pckt07i3dffeBXd+IrOVW5+Z5CPTK4NrAAAAsAo1ewyQpaWl3rFjx6LbAAAAWIiqurW7l/a3b2GL4wAAAHBoEBwBAAAYEhwBOGxt355cfPFsCwCs3potjgMAi7R9e7JlS7J7d7JxY7JtW7K8vOiuAODQ5I4jAIellZVZaNyzZ7ZdWVl0RwBw6BIcATgsbd48u9O4YcNsu3nzojsCgEOXqaoAHJaWl2fTU1dWZqHRNFUAWD3BEYDD1vKywAgATwVTVQEAABgSHAEAABgSHAEAABgSHAEAABgSHAEAABgSHAEAABgSHAGAA7Z9e3LxxbMtAEcOv+MIAByQ7duTLVuS3buTjRuTbdv8TibAkcIdRwDggKyszELjnj2z7crKojsC4GARHAGAA7J58+xO44YNs+3mzYvuCICDxVRVAOCALC/PpqeurMxCo2mqAEcOwREAOGDLywIjwJHIVFUAAACGBEcAAACGBEcAAACGBEcAgAXZvj25+OLZFmA9szgOAMACbN+ebNky+03MjRtnK9ZaeAhYr9xxBABYgJWVWWjcs2e2XVlZdEcAj09wBABYgM2bZ3caN2yYbTdvXnRHAI/PVFUAgAVYXp5NT11ZmYVG01SB9UxwBABYkOVlgRE4NJiqCgAAwJDgCADAYcNPnMDaMFUVAIDDgp84gbXjjiMAAIcFP3ECa0dwBADgsOAnTmDtmKoKAMBhwU+cwNoRHAEAOGz4iZOn1vbtgjgzgiMAAPAYFhtinmccAQCAx7DYEPMERwAA4DEsNsQ8U1UBAIDHsNjQ2jhUnxsVHAEAgP2y2NBT61B+btRUVQAAgIPgUH5uVHAEAAA4CA7l50ZNVQUAADgIDuXnRgVHAACAg+RQfW50IVNVq+qnq+qOqrqzqn5mqj23qm6sqi9M22OmelXVJVW1s6puq6qXzp1n6zT+C1W1da7+sqq6fTrmkqqqg/8tAQAADg8HPThW1YuTvDHJ6UlekuS1VfXCJBcm2dbdpybZNn1OklcnOXV6XZDk0uk8z01yUZLvmc510d6wOY1549xxZ639NwMAADg8LeKO499P8onu/kZ3P5Lk95O8LsnZSa6axlyV5Jzp/dlJ3tczNyc5uqqen+RVSW7s7ge6+8EkNyY5a9r37O6+ubs7yfvmzgUAAMCTtIjgeEeS762q51XVtyV5TZITkxzX3fdOY76c5Ljp/fFJ7p47ftdUG9V37acOAADAKhz0xXG6+3NV9c4kH03yF0k+k2TPPmO6qnqte6mqCzKb/pqTTjpprS8HAABwSFrI4jjdfXl3v6y7vy/Jg0n+KMlXpmmmmbb3TcPvyeyO5F4nTLVR/YT91PfXx2XdvdTdS5s2bfrWvxgAAMBhaFGrqv7taXtSZs83/tck1yfZuzLq1iTXTe+vT3LetLrqGUkemqa03pDkzKo6ZloU58wkN0z7vl5VZ0yrqZ43dy4AAACepEX9juN/q6rnJfnLJG/q7q9V1TuSXFNV5yf5UpIfnsZ+OLPnIHcm+UaSH02S7n6gqt6e5JZp3Nu6+4Hp/U8kuTLJM5N8ZHoBAACwCjVbeJSlpaXesWPHotsAAABYiKq6tbuX9rdvIVNVAQAAOHQIjgAAAAwJjgAAAAwJjgAAAAwJjgAAAAwJjgAAAAwJjgAAAAz5HcdJVd2f5EuL7mM/jk3yZ4tuAgb8jbLe+RtlvfM3ynrnb/TI8Xe6e9P+dgiO61xV7Xi8H+GE9cDfKOudv1HWO3+jrHf+RklMVQUAAOAJCI4AAAAMCY7r32WLbgCegL9R1jt/o6x3/kZZ7/yN4hlHAAAAxtxxBAAAYEhwXKeq6qyq+nxV7ayqCxfdD+yrqk6sqpuq6rNVdWdV/fSie4J9VdWGqvp0Vf3OonuB/amqo6vq2qr6w6r6XFUtL7onmFdVPzv9c/6OqvpgVf2NRffEYgiO61BVbUjyniSvTnJakjdU1WmL7Qoe45EkP9fdpyU5I8mb/J2yDv10ks8tugkY+N+T/F53/70kL4m/V9aRqjo+yU8lWeruFyfZkOTcxXbFogiO69PpSXZ2913dvTvJ1UnOXnBP8CjdfW93f2p6/+eZ/cvO8YvtCv5aVZ2Q5AeSvHfRvcD+VNVzknxfksuTpLt3d/fXFtsVPMZRSZ5ZVUcl+bYk/8+C+2FBBMf16fgkd8993hX/Qs46VlUnJ/mHST6x2E7gUX4tyc8n+eaiG4HHcUqS+5P852lK9Xur6lmLbsZYA/sAAAVSSURBVAr26u57kvyHJH+a5N4kD3X3RxfbFYsiOALfkqr6m0n+W5Kf6e6vL7ofSJKqem2S+7r71kX3AgNHJXlpkku7+x8m+Ysk1jVg3aiqYzKb9XZKkm9P8qyq+peL7YpFERzXp3uSnDj3+YSpButKVT09s9D4ge7+0KL7gTn/OMkPVtWfZDbd/5VV9V8W2xI8xq4ku7p772yNazMLkrBefH+SL3b3/d39l0k+lOQfLbgnFkRwXJ9uSXJqVZ1SVRszewj5+gX3BI9SVZXZczmf6+7/uOh+YF53v7W7T+jukzP7/9CPdbf/Ss660t1fTnJ3VX3nVNqS5LMLbAn29adJzqiqb5v+ub8lFnA6Yh216AZ4rO5+pKrenOSGzFavuqK771xwW7Cvf5zkXyW5vao+M9V+obs/vMCeAA41P5nkA9N/KL4ryY8uuB/4K939iaq6NsmnMltN/dNJLltsVyxKdfeiewAAAGAdM1UVAACAIcERAACAIcERAACAIcERAACAIcERAACAIcERgCNCVXVV/erc539bVb/0FJ37yqp6/VNxrie4zg9V1eeq6qZ96idX1f8893mpqi5Z634AOHIIjgAcKR5O8rqqOnbRjcyrqifzm8rnJ3ljd79in/rJSf4qOHb3ju7+qaegPQBIIjgCcOR4JLMfrv7ZfXfse8ewqv7fabu5qn6/qq6rqruq6h1V9S+q6pNVdXtVvWDuNN9fVTuq6o+q6rXT8Ruq6l1VdUtV3VZV/3ruvP9XVV2f5LP76ecN0/nvqKp3TrV/l+SfJLm8qt61zyHvSPK9VfWZqvrZ6fy/Mx33S1V11XS9L1XV66rqV6bz/15VPX0a97Lpu95aVTdU1fOn+k9V1Wen/q9e3f/0ABzqnsx/5QSAQ917ktxWVb/yJI55SZK/n+SBJHcleW93n15VP53kJ5P8zDTu5CSnJ3lBkpuq6oVJzkvyUHe/vKqekeT/rqqPTuNfmuTF3f3F+YtV1bcneWeSlyV5MMlHq+qc7n5bVb0yyb/t7h379HjhVN8bWDfvs/8FSV6R5LQk25P88+7++ar6rSQ/UFW/m+Q/JTm7u++vqh9J8u+T/Nh07lO6++GqOvpJ/O8GwGFEcATgiNHdX6+q9yX5qST/3wEedkt335skVfXHSfYGv9szC2N7XdPd30zyhaq6K8nfS3Jmku+au5v5nCSnJtmd5JP7hsbJy5OsdPf90zU/kOT7kvz2Afa7Px/p7r+sqtuTbEjye3Pf4eQk35nkxUlurKpMY+6dxtyW5ANV9dvfYg8AHMIERwCONL+W5FNJ/vNc7ZFMj29U1dOSbJzb9/Dc+2/Off5mHv3P0d7nOp2kkvxkd98wv2O6I/gXq2t/VR5Oku7+ZlX9ZXfv7XXvd6gkd3b38n6O/YHMgus/TfKLVfUPuvuRg9E0AOuHZxwBOKJ09wNJrslsoZm9/iSzqaFJ8oNJnr6KU/9QVT1teu7x7yb5fJIbkvybuecIv6OqnvUE5/lkkv+xqo6tqg1J3pDk95/gmD9P8rdW0fNen0+yqaqWpz6fXlUvmkL0id19U5K3ZHbH9G9+C9cB4BDljiMAR6JfTfLmuc+/keS6qvqDzKZxruZu4J9mFvqeneTHu/u/V9V7M5sK+qmazQG9P8k5o5N0971VdWGSmzK7E/i73X3dE1z7tiR7pv6vTPLpJ9N4d++eptNeUlXPyezfD34tyR8l+S9TrZJc0t1fezLnBuDwUH89WwUAAAAey1RVAAAAhgRHAAAAhgRHAAAAhgRHAAAAhgRHAAAAhgRHAAAAhgRHAAAAhgRHAAAAhv5/rfvNW986AbUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "repeat_times = 10\n",
    "X_Dimension = 46\n",
    "\n",
    "debug = True # print some information if needed\n",
    "\n",
    "initial_theta = np.random.randn(X_Dimension) # initialization of the prameters\n",
    "if debug:\n",
    "  print('Random initialization of parameters: {}'.format(initial_theta))\n",
    "\n",
    "# load the training data\n",
    "file = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/vali_as_train.txt'\n",
    "train_list_Qs = load_LETOR4(file=file)\n",
    "\n",
    "#training the model based on gradient descent algorithm\n",
    "optimized_theta, cost_history = reg_gradient_descent(train_list_Qs, initial_theta, learning_rate=0.001, repeat_times=repeat_times)\n",
    "\n",
    "if debug:\n",
    "  print('\\n Optimized parameters:{}'.format(optimized_theta))\n",
    "\n",
    "# evaluate the ranking model by computing its nDCG score\n",
    "# load the test data\n",
    "file = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/test.txt'\n",
    "test_list_Qs = load_LETOR4(file=file)\n",
    "\n",
    "nDCG = evaluate(test_list_Qs=test_list_Qs, optimized_theta=optimized_theta)\n",
    "print('\\n The nDCG score of the optimized ranking model is:', nDCG)\n",
    "\n",
    "\n",
    "# show the cost variation w.r.t. the training process\n",
    "print()\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "ax.set_ylabel('Cost')\n",
    "ax.set_xlabel('Number of times')\n",
    "ax.plot(range(repeat_times), cost_history[:repeat_times], 'b.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KuFfBVUUQZa"
   },
   "source": [
    "### 2.1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4770,
     "status": "ok",
     "timestamp": 1605836575696,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "s-aT9BLoFPAm",
    "outputId": "f22ec6e9-40f6-494a-a0ba-78d3841c7210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ptranking\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/10/1f39cedc6b26bb4fc9588f700f2a18bcec8a08f5f122ad1d47d54fc57324/ptranking-0.0.3-py3-none-any.whl (115kB)\n",
      "\r",
      "\u001b[K     |██▉                             | 10kB 17.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 20kB 22.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 30kB 26.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 40kB 18.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 51kB 16.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 61kB 18.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 71kB 11.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 81kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 92kB 12.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 102kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 112kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 122kB 11.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from ptranking) (4.41.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ptranking) (1.18.5)\n",
      "Installing collected packages: ptranking\n",
      "Successfully installed ptranking-0.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install ptranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2SvBcfk2sL2"
   },
   "source": [
    "### 2.2 Import necessary classes provided by PTRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x77KDXpnUrvR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from ptranking.data.data_utils import LTRDataset, SPLIT_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbFRHchC25Zh"
   },
   "source": [
    "### 2.3 Define a neural ranking class\n",
    "\n",
    "For more details, please refer to: https://wildltr.github.io/ptranking/how_to_start/Develop_A_New_Model/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkvzo9_EWwly"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from ptranking.base.ranker import NeuralRanker\n",
    "\n",
    "mse = nn.MSELoss() # mean square error function provided by PyTorch\n",
    "\n",
    "class MLIRMSE(NeuralRanker):\n",
    "\tdef __init__(self, sf_para_dict=None, gpu=False, device=None):\n",
    "\t\tsuper(MLIRMSE, self).__init__(id='RankMSE', sf_para_dict=sf_para_dict, gpu=gpu, device=device)\n",
    "\t\tself.TL_AF = self.get_tl_af()\n",
    "\n",
    "\tdef inner_train(self, batch_pred, batch_label, **kwargs):\n",
    "\t\t'''\n",
    "\t\t:param batch_preds: [batch, ranking_size] each row represents the relevance predictions for documents within a ltr_adhoc\n",
    "\t\t:param batch_stds: [batch, ranking_size] each row represents the standard relevance grades for documents within a ltr_adhoc\n",
    "\t\t:return:\n",
    "\t\t'''\n",
    "\n",
    "\t\tbatch_loss = mse(batch_pred, batch_label)\n",
    "\t\t# gradient back-propagation\n",
    "\t\tself.optimizer.zero_grad()\t\n",
    "\t\tbatch_loss.backward()\n",
    "\t\tself.optimizer.step()\n",
    "\n",
    "\t\treturn batch_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShH5-C2J3Awk"
   },
   "source": [
    "### 2.4 Define a neural scoring fuction\n",
    "\n",
    "It is a component of the NeuralRanker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTfjsT5eYW5y"
   },
   "outputs": [],
   "source": [
    "from ptranking.ltr_adhoc.eval.parameter import ScoringFunctionParameter\n",
    "\n",
    "\n",
    "class MLIRSFP(ScoringFunctionParameter):\n",
    "    \"\"\"\n",
    "    The parameter class w.r.t. a neural scoring fuction\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MLIRSFP, self).__init__()\n",
    "\n",
    "    def default_para_dict(self):\n",
    "        \"\"\"\n",
    "        A default setting of the hyper-parameters of the stump neural scoring function.\n",
    "        \"\"\"\n",
    "        # feed-forward neural networks\n",
    "        ffnns_para_dict = dict(num_layers=5, HD_AF='R', HN_AF='R', TL_AF='S', apply_tl_af=True, BN=True, RD=False, FBN=False)\n",
    "\n",
    "        sf_para_dict = dict()\n",
    "        sf_para_dict['id'] = self.model_id\n",
    "        sf_para_dict[self.model_id] = ffnns_para_dict\n",
    "\n",
    "        self.sf_para_dict = sf_para_dict\n",
    "        return sf_para_dict\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "My32Q77g3HE8"
   },
   "source": [
    "### 2.5 Perform learning-to-rank based on PTRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6096,
     "status": "ok",
     "timestamp": 1605839288723,
     "user": {
      "displayName": "Hai-Tao Yu",
      "photoUrl": "",
      "userId": "06698935547344579595"
     },
     "user_tz": -540
    },
    "id": "oFNG0J0YUjPw",
    "outputId": "c42ab891-3a24-4a8d-eb00-84e93cf6bb6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4747, 0.4781, 0.5191])\n"
     ]
    }
   ],
   "source": [
    "from ptranking.data.data_utils import get_data_meta\n",
    "from ptranking.ltr_adhoc.eval.eval_utils import ndcg_at_ks, ndcg_at_k\n",
    "from ptranking.metric.adhoc_metric import torch_nDCG_at_k, torch_nDCG_at_ks\n",
    "\n",
    "gpu, device = False, None\n",
    "\n",
    "##- Data loading -##\n",
    "file_train = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/vali_as_train.txt'\n",
    "\n",
    "file_test = '/content/drive/My Drive/Teaching/2020/KLIS-MLIR-2020/Data/test.txt'\n",
    "\n",
    "train_data = LTRDataset(data_id='MQ2007_Super', file=file_train, split_type=SPLIT_TYPE.Train, batch_size=1, shuffle=True, presort=True, data_dict=None, eval_dict=None, buffer=False)\n",
    "\n",
    "test_data = LTRDataset(data_id='MQ2007_Super', file=file_test, split_type=SPLIT_TYPE.Test, shuffle=False, data_dict=None, batch_size=1, buffer=False)\n",
    "\n",
    "data_meta = get_data_meta(data_id='MQ2007_Super')\n",
    "\n",
    "sf_para_dict = MLIRSFP().default_para_dict()\n",
    "\n",
    "sf_para_dict['ffnns'].update(dict(num_features=data_meta['num_features']))\n",
    "\n",
    "\n",
    "# Initialize the ranking class as a ranker\n",
    "mlir_ranker = MLIRMSE(sf_para_dict=sf_para_dict)\n",
    "\n",
    "# Training\n",
    "epoch_loss = torch.cuda.FloatTensor([0.0]) if gpu else torch.FloatTensor([0.0])\n",
    "\n",
    "# Training for each query\n",
    "for qid, batch_rankings, batch_stds in train_data: # _, [batch, ranking_size, num_features], [batch, ranking_size]\n",
    "    if gpu: batch_rankings, batch_stds = batch_rankings.to(device), batch_stds.to(device)\n",
    "\n",
    "    batch_loss, stop_training = mlir_ranker.train(batch_rankings, batch_stds, qid=qid)\n",
    "\n",
    "    #print(batch_loss)\n",
    "    epoch_loss += batch_loss.item()\n",
    "\n",
    "\n",
    "# Testing\n",
    "ks=[1, 5, 10]\n",
    "sum_ndcg_at_ks = torch.zeros(len(ks))\n",
    "cnt = torch.zeros(1)\n",
    "already_sorted = True if test_data.presort else False\n",
    "for qid, batch_ranking, batch_labels in test_data: # _, [batch, ranking_size, num_features], [batch, ranking_size]\n",
    "\n",
    "    if torch.sum(batch_labels) <=0: # filter dumb queries\n",
    "      continue\n",
    "\n",
    "    if gpu: batch_ranking = batch_ranking.to(device)\n",
    "    batch_rele_preds = mlir_ranker.predict(batch_ranking)\n",
    "    if gpu: batch_rele_preds = batch_rele_preds.cpu()\n",
    "\n",
    "    _, batch_sorted_inds = torch.sort(batch_rele_preds, dim=1, descending=True)\n",
    "\n",
    "    batch_sys_sorted_labels = torch.gather(batch_labels, dim=1, index=batch_sorted_inds)\n",
    "    if already_sorted:\n",
    "        batch_ideal_sorted_labels = batch_labels\n",
    "    else:\n",
    "        batch_ideal_sorted_labels, _ = torch.sort(batch_labels, dim=1, descending=True)\n",
    "\n",
    "    batch_ndcg_at_ks = torch_nDCG_at_ks(batch_sys_sorted_labels=batch_sys_sorted_labels, batch_ideal_sorted_labels=batch_ideal_sorted_labels, ks=ks)\n",
    "\n",
    "    # default batch_size=1 due to testing data\n",
    "    sum_ndcg_at_ks = torch.add(sum_ndcg_at_ks, torch.squeeze(batch_ndcg_at_ks, dim=0))\n",
    "    cnt += 1\n",
    "\n",
    "avg_ndcg_at_ks = sum_ndcg_at_ks/cnt\n",
    "print(avg_ndcg_at_ks)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lecture_7_Beginning of Learning-to-Rank.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
