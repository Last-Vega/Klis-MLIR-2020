{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task is to develop a new ranking method, and the requirements are as follows: \n",
    "1. Take the the provided example programs, such as \n",
    "(1) Lecture_7_Beginning of Learning-to-Rank.ipynb \n",
    "(2) Lecture_8_Ranknet.ipynb \n",
    "as a reference \n",
    "\n",
    "2. Using the provided dataset (Manaba -> Lecture-6), namely using vali_as_train.txt as the training data, and using test.txt as the test data \n",
    "\n",
    "3. Develop your own ranking method. Using PyTorch is recommended, but it is not a must. \n",
    "\n",
    "4. Please compute the nDCG score of your method based on the test data: test.txt \n",
    "\n",
    "5. If you used some reference papers, please cite them in the end. \n",
    "\n",
    "Note: \n",
    "(1) Please submit it as a Jupyter Notebook file, and add some necessary descriptions. \n",
    "(2) If two students submit the duplicate files, there will be no grade for all of them. \n",
    "(3) Please make sure that there is no bug within your Jupyter Notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function for loading data\n",
    "def load_LETOR4(file, num_features=46):\n",
    "    '''\n",
    "    :param file: the input file\n",
    "    :param num_features: the number of features\n",
    "    :return: the list of tuples, each tuple consists of qid, doc_reprs, doc_labels\n",
    "    '''\n",
    "  \n",
    "    feature_cols = [str(f_index) for f_index in range(1, num_features + 1)]\n",
    "\n",
    "    df = pd.read_csv(file, sep=\" \", header=None)\n",
    "    df.drop(columns=df.columns[[-2, -3, -5, -6, -8, -9]], axis=1, inplace=True)  # remove redundant keys\n",
    "    assert num_features == len(df.columns) - 5\n",
    "\n",
    "    for c in range(1, num_features +2): # remove keys per column from key:value\n",
    "        df.iloc[:, c] = df.iloc[:, c].apply(lambda x: x.split(\":\")[1])\n",
    "\n",
    "    df.columns = ['rele_truth', 'qid'] + feature_cols + ['#docid', 'inc', 'prob']\n",
    "\n",
    "    for c in ['rele_truth'] + feature_cols:\n",
    "        df[c] = df[c].astype(np.float32)\n",
    "\n",
    "    df['rele_binary'] = (df['rele_truth'] > 0).astype(np.float32)  # additional binarized column for later filtering\n",
    "\n",
    "    list_Qs = []\n",
    "    qids = df.qid.unique()\n",
    "    np.random.shuffle(qids)\n",
    "    for qid in qids:\n",
    "        sorted_qdf = df[df.qid == qid].sort_values('rele_truth', ascending=False)\n",
    "\n",
    "        doc_reprs = sorted_qdf[feature_cols].values\n",
    "        doc_labels = sorted_qdf['rele_truth'].values\n",
    "\n",
    "        list_Qs.append((qid, doc_reprs, doc_labels))\n",
    "\n",
    "    #if buffer: pickle_save(list_Qs, file=perquery_file)\n",
    "\n",
    "    return list_Qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local jupyter notebook\n",
    "train_file = './vali_as_train.txt'\n",
    "test_file = './test.txt'\n",
    "\n",
    "train_list_Qs = load_LETOR4(file=train_file)\n",
    "test_list_Qs = load_LETOR4(file=test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
