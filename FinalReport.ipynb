{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Report \n",
    "####  Corse Name: Machine Learning and Information Retrieval System\n",
    "####  Student ID: 201811552\n",
    "####  Name: Shingo Watanabe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Final Report  Overall\n",
    "I implemented Ranking method. In the process of researching Ranknet, I found out that there are three types of methods: pointwise, pairwise, and listnet methods. This time I created a ranking model using the pairwise method. I used Relu for the activation function and Adam for the optimization function. To create the model, I used the ideas in the following references.\n",
    "\n",
    "\n",
    "#### References\n",
    "1. 'From RankNet to LambdaRank to LambdaMART' https://www.microsoft.com/en-us/research/uploads/prod/2016/02/MSR-TR-2010-82.pdf\n",
    "- 'PyTorchを用いたRankNetの実装' https://www.szdrblog.info/entry/2018/12/23/234612\n",
    "- 'PytorchによるRankNet' https://ryo59.github.io/ranknet.html\n",
    "- 'RankNetを実装してランキング学習' https://qiita.com/kzkadc/items/c358338f0d8bd764f514"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Import necessary modules and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import torch\n",
    "from ptranking.data.data_utils import LTRDataset, SPLIT_TYPE\n",
    "import torch.nn as nn\n",
    "from ptranking.ltr_adhoc.eval.parameter import ScoringFunctionParameter\n",
    "from ptranking.ltr_adhoc.eval.eval_utils import ndcg_at_ks, ndcg_at_k\n",
    "from ptranking.metric.adhoc_metric import torch_nDCG_at_k, torch_nDCG_at_ks\n",
    "import torch.nn.functional as F\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Define Neural Network: RankNet\n",
    "\n",
    "- init : Inherit and initialize the RankNet class. \n",
    "- forward: Repeat the calculation of the input and application of the activation function in the forward direction.\n",
    "- loss: Computation of loss functions using pairwise methods.\n",
    "- predict: Function for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNet(nn.Module):\n",
    "    def __init__(self, trial, num_layer, input_dim, h_dim, lr_rate):\n",
    "        super(RankNet, self).__init__()\n",
    "        self.activation = get_activation(trial)\n",
    "        # first layer\n",
    "        self.fc = nn.ModuleList([nn.Linear(input_dim, h_dim[0])])\n",
    "        # after first layer\n",
    "        for i in range(1, num_layer):\n",
    "            self.fc.append(nn.Linear(h_dim[i-1], h_dim[i]))\n",
    "        self.dropout = nn.Dropout(lr_rate)\n",
    "\n",
    "        self.fc_last = nn.Linear(h_dim[i], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, l in enumerate(self.fc):\n",
    "            x = self.dropout(x)\n",
    "            x = l(x)\n",
    "            x = self.activation(x)\n",
    "        x = self.fc_last(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, torch_batch_rankings, torch_batch_std_labels):\n",
    "\n",
    "        # Make a pair from the model predictions\n",
    "        batch_pred = self.forward(torch_batch_rankings)  # batch_pred = [40,1]\n",
    "        batch_pred_dim = torch.squeeze(batch_pred, 1) # batch_pred_dim = [40]\n",
    "        batch_pred_diffs = batch_pred - torch.unsqueeze(batch_pred_dim, 0)  # batch_pred_diffs=[40, 40]\n",
    "\n",
    "        # Make a pair from the relevance of the label\n",
    "        batch_std = torch_batch_std_labels # batch_std = [40]\n",
    "        batch_std_diffs = torch.unsqueeze(batch_std, 1) - torch.unsqueeze(batch_std, 0) # batch_std_diffs=[40, 40]\n",
    "\n",
    "        batch_Sij = torch.clamp(batch_std_diffs, -1, 1)\n",
    "\n",
    "        sigma = 1.0\n",
    "        batch_loss_1st = 0.5 * sigma * batch_pred_diffs * (1.0 - batch_Sij)\n",
    "        batch_loss_2nd = torch.log(torch.exp(-sigma * batch_pred_diffs) + 1.0)\n",
    "\n",
    "        # Calculate loss outside diagonal\n",
    "        diagona = 1 - torch.eye(batch_loss_1st.shape[0])\n",
    "        batch_loss = (batch_loss_1st + batch_loss_2nd) * diagona\n",
    "        combination = (batch_loss_1st.shape[0] * (batch_loss_1st.shape[0] - 1)) / 2\n",
    "\n",
    "        batch_loss_triu = (torch.sum(batch_loss) / 2) / combination\n",
    "\n",
    "        return batch_loss_triu\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Define optimization and activation function\n",
    "\n",
    "- get_optimizer: Optimization function is Adam.\n",
    "- get_activation: Activation function is Relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(trial, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "def get_activation(trial):\n",
    "    activation = F.relu\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, optimizer):\n",
    "    model.train()\n",
    "    for qid, torch_batch_rankings, torch_batch_std_labels in train_data:\n",
    "        data, target = torch_batch_rankings, torch_batch_std_labels\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(data, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data):\n",
    "    # Testing\n",
    "    ks=[1, 5, 10]\n",
    "    sum_ndcg_at_ks = torch.zeros(len(ks))\n",
    "    cnt = torch.zeros(1)\n",
    "    for qid, batch_ranking, batch_labels in test_data:\n",
    "        if torch.sum(batch_labels) <=0: # filter dumb queries\n",
    "            continue\n",
    "\n",
    "        batch_rele_preds = model.predict(batch_ranking)\n",
    "        pred_ar = batch_rele_preds.squeeze(1)\n",
    "        # _, order = torch.sort(batch_labels, descending=True)\n",
    "        # y_pred_sorted = batch_labels[0][order]\n",
    "\n",
    "        _, batch_sorted_inds = torch.sort(batch_rele_preds, dim=1, descending=True)\n",
    "        # print(batch_sorted_inds[0].T)\n",
    "        # exit()\n",
    "        batch_sys_sorted_labels = torch.gather(batch_labels, dim=1, index=batch_sorted_inds[0].T)\n",
    "        # print(batch_sys_sorted_labels)\n",
    "        # exit()\n",
    "        batch_ideal_sorted_labels, _ = torch.sort(batch_labels, dim=1, descending=True)\n",
    "        # print(batch_ideal_sorted_labels)\n",
    "\n",
    "        batch_ndcg_at_ks = torch_nDCG_at_ks(\n",
    "            batch_sys_sorted_labels=batch_sys_sorted_labels,\n",
    "            batch_ideal_sorted_labels=batch_ideal_sorted_labels,\n",
    "            ks=ks\n",
    "        )\n",
    "\n",
    "        # default batch_size=1 due to testing data\n",
    "        sum_ndcg_at_ks = torch.add(sum_ndcg_at_ks, torch.squeeze(batch_ndcg_at_ks, dim=0))\n",
    "        cnt += 1\n",
    "\n",
    "    avg_ndcg_at_ks = sum_ndcg_at_ks/cnt\n",
    "    print('ndcg =', avg_ndcg_at_ks)\n",
    "    return avg_ndcg_at_ks[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Run some functions\n",
    "- objective: Pass data to train and test and run some function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    train_file = './vali_as_train.txt'\n",
    "    test_file = './test.txt'\n",
    "\n",
    "    train_data = LTRDataset(\n",
    "                            data_id='MQ2007_Super',\n",
    "                            file=train_file,\n",
    "                            split_type=SPLIT_TYPE.Train,\n",
    "                            batch_size=1,\n",
    "                            shuffle=True,\n",
    "                            presort=True,\n",
    "                            data_dict=None,\n",
    "                            eval_dict=None,\n",
    "                            buffer=False\n",
    "                        )\n",
    "\n",
    "    test_data = LTRDataset(\n",
    "                            data_id='MQ2007_Super',\n",
    "                            file=test_file,\n",
    "                            split_type=SPLIT_TYPE.Test,\n",
    "                            shuffle=False,\n",
    "                            data_dict=None,\n",
    "                            batch_size=1,\n",
    "                            buffer=False\n",
    "                        )\n",
    "    num_layer = trial.suggest_int('num_layer', 3, 7)\n",
    "\n",
    "    h_dim = [int(trial.suggest_discrete_uniform(\"h_dim_\"+str(i), 16, 128, 16)) for i in range(num_layer)]\n",
    "\n",
    "    lr_rate = trial.suggest_uniform(\"dropout_l\", 0.2, 0.5)\n",
    "\n",
    "    ranknet = RankNet(trial, num_layer, 46, h_dim, lr_rate)\n",
    "    optimizer = get_optimizer(trial, ranknet)\n",
    "    for step in range(EPOCH):\n",
    "        train(ranknet, train_data, optimizer)\n",
    "        ndcg = test(ranknet, test_data)\n",
    "\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-04 11:44:49,905]\u001b[0m A new study created in memory with name: no-name-9543953d-4c42-4ca3-b247-7279d5857fe7\u001b[0m\n",
      "\u001b[32m[I 2021-01-04 11:44:52,545]\u001b[0m Trial 0 finished with value: 0.28270575404167175 and parameters: {'num_layer': 6, 'h_dim_0': 112.0, 'h_dim_1': 48.0, 'h_dim_2': 112.0, 'h_dim_3': 16.0, 'h_dim_4': 128.0, 'h_dim_5': 64.0, 'dropout_l': 0.35003328805771716}. Best is trial 0 with value: 0.28270575404167175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg = tensor([0.1276, 0.2234, 0.2827])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-04 11:44:55,514]\u001b[0m Trial 1 finished with value: 0.28270575404167175 and parameters: {'num_layer': 7, 'h_dim_0': 96.0, 'h_dim_1': 96.0, 'h_dim_2': 112.0, 'h_dim_3': 128.0, 'h_dim_4': 16.0, 'h_dim_5': 16.0, 'h_dim_6': 112.0, 'dropout_l': 0.41825214020750034}. Best is trial 0 with value: 0.28270575404167175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg = tensor([0.1276, 0.2234, 0.2827])\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 1\n",
    "\n",
    "TRIAL_SIZE = 2\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=TRIAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
